# Вероятность как математическая конструкция {#prob}

{{< include other/_symbols.qmd >}}

```{r opts, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, error=FALSE}
knitr::opts_chunk$set(echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, error=FALSE)
```

```{r pkgs}
library(tidyverse)
theme_set(theme_bw())
```


:::{.intro}
Озадачимся более серьезно построением «вероятности» с опорой на фундамент всей современной математики --- теорию множеств.
:::


## Эксперименты со случайным исходом {#prob-randexp}

:::{.lab-senior}
:::

Вернемся к концепции **эксперимента со случайным исходом (случайного эксперимента)**, который как мы выяснили ранее(HREF), происходит каждый раз в момент измерения. Нам необходима некая математическая модель такого эксперимента, чтобы мы могли далее с этим феноменом работать.

Математическая модель случайного эксперимента содержит несколько требований:

1. **Недетерминированность исхода** <br> 
Мы не можем знать наверняка, что произойдет в конкретном эксперименте. В этом смысле бросание теннисного мяса с заданной высоты не является случайным экспериментом, так как исход абсолютно точно известен заранее --- мяч совершит движение вертикально вниз и ударится оземь.
1. **Принципиальная возможность повторения эксперимента** (во времени и/или в пространстве) <br>
Мы можем повторить наш эксперимент сколь угодно большое количество раз. Причем эти повторения могут быть разнесены друг от друга во времени (100 раз подряд подбросить одну и ту же монетку) или в пространстве (одновременно подбросить 100 монеток). В этом смысле сдача экзамена некоторым студентом не является случайным экспериментом --- студент сдает экзамен [в идеале] один раз[^exam-times].
1. **Неизменность условий эксперимента** <br>
Во всех повторениях эксперимента условия его проведения не изменяются. В этом смысле даже если рассмотреть ситуацию трёхкратной сдачи экзамена некоторым студентом, она не является случайным экспериментом, так как студент [наверное, хотелось бы думать, что] готовится к пересдачам, соответственно, условия сдачи экзамена меняются.
1. **В одном повторении эксперимента некий исход может либо реализовать, либо не реализоваться** <br>
Данное требование позволяет ввести такую характеристику исхода случайного эксперимента как *частота*. <br>
Исход $A$ имеет [относительную] частоту $\displaystyle \frac{n(A)}{n}$, если в $n$ повторениях случайного эксперимента этот исход реализовался $n(A)$ раз.
1. **Статистическая устойчивость частоты** <br>
Под этим понимают две вещи:
    - с ростом числа повторений случайного эксперимента относительная частота события $A$ должна приближаться к некоторому значению [@serdobolskaya2019] (@fig-prob-stat-stability-1)
    - в разных сериях случайных экспериментов относительная частота события $A$ (при достаточно большом количестве повторений случайного эксперимента) не должна сильно меняться [@erlikh2019] (@fig-prob-stat-stability-2).

[^exam-times]: Окей, максимум --- три. Этого всё равно не достаточно для выполнения данного требования.

```{r prob-stat-stability-plots}
set.seed(123)

tibble(n = seq(1, 5000, by = 5),
       p = n %>% 
  map(sample, x = 1:6, replace = TRUE) %>% 
  map(table) %>% 
  map(.[1]) %>% 
  unlist() %>% 
  `/`(n)
  ) %>% 
  ggplot(aes(n, p)) +
  geom_point(size = 1) +
  geom_hline(yintercept = 1/6,
             color = "#9AEBC6",
             linewidth = 1) +
  ylim(0, 1) +
  labs(x = "Количество случайных экспериментов",
       y = "Относительная частота") -> plot1


set.seed(956)
sample(1:6, 500*1000, replace = TRUE) %>% 
  matrix(ncol = 1000) %>% 
  apply(2, function(x) sum(x == 1)) %>% 
  `/`(500) %>% 
  tibble(n = 1:1000,
         p = .) %>% 
  ggplot(aes(x = n,
             y = p)) +
  geom_point(size = 1) +
  geom_hline(yintercept = 1/6,
             color = "#36D38C",
             linewidth = 1) +
  ylim(0, 1) +
  labs(x = "Номер серии экспериментов",
       y = "Относительная частота") -> plot2
```

```{r prob-stat-stability-fig}
#| label: fig-prob-stat-stability
#| fig-cap: "Статистическая устойчивость"
#| fig-subcap:
#|   - "С ростом числа испытания относительная частота приближается к некоторому значению"
#|   - "В разных сериях испытаний относительная частота примерно постоянна"
#| layout-ncol: 2

print(plot1)
print(plot2)
```


Значение, в которому стремится относительная частота исхода случайного эксперимента, естественно назвать *вероятностью этого исхода*:

$$
\prob (A) \approx \frac{n(A)}{n}, \, n \to \infty
$$

Окей... Но ведь мы это же самое говорили, когда рассматривали статистическую интерпретацию вероятности! В чем здесь проблема?


### Несостоятельность $\prob (A) \approx \frac{n(A)}{n}$ как определения вероятности {#prob-not-freq}

:::{.lab-senior}
:::

Если мы внимательно присмотримся к записи $\displaystyle \prob (A) \approx \frac{n(A)}{n}, \, n \to \infty$, то обнаружим, что в качестве математического определения вероятности она совершенно не годится [@serdobolskaya2019].

* Во-первых, его невозможно [эмпирически] проверить --- необходимо бесконечно время ($n \to \infty$), а значит, изменятся условия эксперимента и не будет выполнено соответствующее требование модели случайного эксперимента.
* Во-вторых, математика не очень любит приближённые равенства. Можно было бы выкрутиться пределом, и сказать, что $\displaystyle \prob (A) = \lim_{n \to \infty} \frac{n(A)}{n}$), но это нас на спасёт. Здесь слева от знака равенства стоит число $\prob (A)$, а частное $\displaystyle  \frac{n(A)}{n}$ под знаком предела --- *случайное* число, поскольку случаен и сам исход $A$. В каком-то смысле относительная частота ещё более случайная, чем исход $A$, так как исход может либо реализоваться, либо нет, а частота может принимать любое значение от $0$ до $1$ c шагом $\displaystyle \frac{1}{n}$.
    * Тогда необходимо определить предел последовательности случайных чисел! Но и здесь возникает проблема --- разность между вероятность и частотой также случайна, поэтому определить предел аналогично тому, как это делается в математическом анализе, не получится.
* Однако есть другая проблема --- «концептуальная» --- равенство $\displaystyle \prob (A) = \lim_{n \to \infty} \frac{n(A)}{n}$ зациклено само на себе. Мы пытаемся определить вероятность, используя частоту, но поведение частоты в случайном эксперименте определяется тем, как задана вероятность в той или иной математической модели.

Таким образом, это выражение не может быть математическим определением, однако оно может быть теоремой теории вероятности, которую мы в виде приближенного равенства сможем использовать в эмпирической проверке расчётов. Для вычисления же самой вероятности необходимо построить математическую конструкцию вероятности. Решением этой задачи и занимается теория вероятности.


## Элементарные исходы и события {#prob-events}
:::{.lab-senior}
:::

Определимся концептуально, что **вероятность --- это мера множества**. **Мера** --- это правильно, которое приписывает множеству *числовое значение*. Мерой как математической конструкцией занимается теория меры(HREF), однако можно найти и хорошо знакомых нам из практики представителей меры --- это, например, длина, площадь, объем или масса. Вероятность является ещё одной мерой, правда, найти ей осязаемый физический аналог оказывается сложнее.

Тем не менее, мы обозначили, что есть некоторое множество, для которого вероятность является мерой. Надо разобраться в том, что это такое за множество.

Пусть есть некоторый эксперимент со случайным исходом. Мы знаем, что в рамках этого эксперимента может произойти, но на можем сказать, что именно произойдет в конкретном случайном эксперименте. Обозначим каждый из возможных исходов [в одном повторении случайного эксперимента] как $\omega$ и назовём **элементарным исходом**[^elem-event].

[^elem-event]: Также встречается термин «элементарное событие».

Если мы соберем все возможные элементарные исходы случайного эксперимента в мешок, то получим **множество элементарных исходов**[^Omega], обозначаемое $\Omega$.

[^Omega]: Также используется термин «пространство элементарных исходов (событий)», однако он в данном случае не совсем корректен. В математике термин «пространство» подразумевает, что между элементами есть какие-либо отношения, однако никаких отношений между элементарными исходами во множестве элементарных исходов нет. Это буквально мешок, в который собрали все элементарных исходы какого-то конкретного случайного эксперимента.

Приведем примеры множеств элементарных исходов. Начнем с чего-то суперклассического. Рассмотрим следующий случайный эксперимент: «один раз брошена монета». Тогда 

$$
\Omega = \{ \omega_1, \omega_2 \},
$$

где $\omega_1$ --- «монета упада “орлом” вверх», $\omega_2$ --- «монета упала “решкой” вверх». Множество элементарных исходов в этой случае состоит всего из двух элементов.

Другой пример: «один раз брошен игральный кубик». В этом случае множество элементарных исходов состоит из шести элементов:

$$
\Omega = \{ \omega_1, \omega_2, \omega_3, \omega_4, \omega_5, \omega_6 \},
$${#eq-dice-omega}

где 

* $\omega_1$ --- «выпала грань с одной точкой», 
* $\omega_2$ --- «выпала грань с двумя точками»,
* $\omega_3$ --- «выпала грань с тремя точками», 
* $\omega_4$ --- «выпала грань с четырьмя точками», 
* $\omega_5$ --- «выпала грань с пятью точками», 
* $\omega_6$ --- «выпала грань с шестью точками».

:::{.callout-note}
###### Модель vs реальность

Конечно, множество элементарных исходов --- это *модель*, и как и в любой модели, в ней присутствует ряд упрощений. Так, не рассматриваются события, «монета упала на ребро» или «игральный кубик упал на ребро», а события «монета упала на стол “орлом” вверх» и «монета упала на пол “орлом” вверх» считаются один и тем же событием. Однако мы пользуемся такими моделями для описания реальных экспериментов, если подобные идеализации, во-первых, адекватно, а во-вторых, вполне хорошо приближают реальность.

:::

Приведем ещё примеры множеств элементарных исходов, более близким к психологии. Случайный эксперимент: «респондент отвечает на вопрос опросника, используя пятибалльную шкалу Ликерта». Тогда

$$
\Omega = \{ \omega_1, \omega_2, \omega_3, \omega_4, \omega_5 \},
$$

где 

* $\omega_1$ --- «респондент выбрал ответ <1>», 
* $\omega_2$ --- «респондент выбрал ответ <2>»,
* $\omega_3$ --- «респондент выбрал ответ <3>», 
* $\omega_4$ --- «респондент выбрал ответ <4>», 
* $\omega_5$ --- «респондент выбрал ответ <5>».

Случайный эксперимент: «респондент заполняет опросник STAI»[^STAI]. Тогда множество элементарных исходов будет таким:

[^STAI]: Шкала тревоги Спилбергера-Ханина (State-Trait Anxiety Inventory, STAI) [@khanin1976; @zaytsev2011]

$$
\Omega = \{ (\omega_{1i}, \omega_{2j}) \such 20 \leq i,j \leq 80\},
$${#eq-stai-omega}

где $\omega_{1i}$ --- «респондент набрал $i$ баллов по шкале ситуативной тревожности», $\omega_{2}$ --- «респондент набрал $j$ баллов по шкале личностной тревожности».

Случайный эксперимент: «неподготовленный студент решает тест по курсу “Психодиагностика и основы психометрики” из 30 заданий, каждое из которые оценивается дихотомически». Тогда множество элементарных исходов для балла за тест будет следующим:

$$
\Omega = \{ \omega_{i} \such 0 \leq i \leq 30 \},
$${#eq-psydiag-omega}

где $\omega_{i}$ --- «студент набрал $i$ баллов за тест».

И так далее. Для каждого случайного эксперимента мы можем описать множество элементарных исходов.

Однако сами элементарные исходы на часто не очень интересуют. Интереснее рассматривать «неэлементарные» исходы, так как они будут соответствовать более содержательным вопросам. Так, например, если считать, что тест по «Психодиагностике и основам психометрики» сдан, если студент набрал не менее 20 баллов, то логично интересоваться событием $A$ «тест сдан», которые состоит из следующих элементарных исходов из $\Omega$ (@eq-psydiag-omega):

$$
A = \{ \omega_{i} \such 20 \leq i \leq 30 \}
$$

Или же рассмотреть событие $A$ «у респондента низкая ситуативная и личностная тревожность» (@eq-stai-omega):

$$
A = \{ (\omega_{1i}, \omega_{2j}) \such 20 \leq i,j \leq 30\}
$$

Ну, или же вернуться к истокам, и изучить событие «на игральной кости выпало четное число очков» (@eq-dice-omega):

$$
A = \{ \omega_2, \omega_4, \omega_6 \}
$$

Таким образом, когда мы говорим о «неэлементарных» события, которые далее будем называться просто **событиями**, мы рассматриваем подмножества $A \subseteq \Omega$.

Получается, что **вероятность --- это мера множества элементарных исходов**.

:::{.callout-note}
###### Элементарные исходы, множество элементарных исходов, события

Итак, зафиксируем введенные обозначения и термины.

* В случайном эксперименте может реализоваться некоторое количество **элементарных исходов** $\omega$.
* Все элементарные исходы составляют **множество элементарных исходов** $\Omega$:

$$
\Omega = \{ \omega_1, \omega_2, \ldots, \omega_n, \ldots \}
$$

* **Любое событие** $A$ является подмножеством множества элементарных исходов $\Omega$:

$$
A \subseteq \Omega
$$

:::


### Как может быть устроено $\Omega$? {#prob-omega-types}

:::{.lab-senior}
:::

Выше мы рассматривали примеры множеств элементарных исходов с конечным числом элементов. Здесь все достаточно понятно. А может ли число элементарных исходов быть бесконечным?

Да, по крайней мере, в математической модели. Например, следующий случайный эксперимент: «монету бросают до первого выпадения “орла”». Тогда множество элементарных исходов примет следующий вид:

$$
\Omega = \{\omega_1, \omega_2, \ldots, \omega_n, \ldots\},
$$

где 

* $\omega_1 = \text{H}$,
* $\omega_1 = \text{TH}$,
* $\vdots$
* $\omega_n = \underbrace{\text{T..T}}_{n-1}\text{H}$,
* $\text{H}$ --- «орёл» («head»), $\text{T}$ --- «решка» («tail»).

В этом случае множество элементарных исходов $\Omega$ равномощно множеству натуральных чисел $\setN$ --- $|\Omega| = |\setN|$--- то есть является *счётным*. Такие множество элементарных исходов встречаются в психологических исследованиях примерно никогда, поэтому на них останавливаться мы не будем, но будем иметь их в виду.

Также в математике есть множества, которые *не являются конечными*, и *не являются счетными*. Они тоже используются в математических моделях случайных экспериментов. Например, ситуация измерения температуры. Пусть мы решили измерить температуру за окном в июле. Множество элементарных исходов такого случайного эксперимента будет описываться так:

$$
\Omega = [T_\min, T_\max],
$$

где $T_\min = 15^\circ \text{C}$, $T_\max = 35^\circ \text{C}$. При этом температура может быть абсолютно любым значением из заданного диапазона.

Приведем пример из области психологии. Пусть у нас есть эксперимент, в котором измеряется время реакции (скажем, задача лексического решения). Тогда зададим множество элементарных исходов так:

$$
\Omega = [t_\min, t_\max],
$$

где, скажем, $t_\min = 0.3 \, \text{c}$, $t_\max = 1.5 \,\text{c}$. При этом время реакции может быть абсолютно любым значением из заданного диапазона. О границах диапазона можно поразмышлять, но в данном случае это не очень существенно, важно, что внутри границ содержится бесконечно много значений, причем эта бесконечность больше, чем количество натуральных чисел $|\setN|$.

Таким образом, если мы хотим описать эксперимент с помощью $\Omega$, нам надо иметь в виду, что это множество может быть абсолютно любой природы с точки зрения количества элементов. Это сделает нам некоторые проблемы, но о них позже.


### Операции над событиями {#prop-events-operations}

:::{.lab-senior}
:::

Напомним себе, что мы пытаемся построить конструкцию вероятности, и дошли до того, что определили события как подмножества множества элементарных исходов. Чтобы далее работать с событиями, нам нужны какие-то операции над нами. Вполне естественно, раз уж мы заговорили о множествах, чтобы операции над событиями отражали операции над множествами. Ниже представлены эти соотношения (@tbl-evets-set).

::: {#tbl-evets-set}

|                                 События                                	|                                                                         Множества                                                                        	|
|:----------------------------------------------------------------------:	|:--------------------------------------------------------------------------------------------------------------------------------------------------------:	|
|                       $\omega$ влечёт событие $A$                      	|                                                                    $$ \omega \in A $$                                                                    	|
|     Событие $A$ состоит из элементарных исходов, которые влекут $A$    	|                                          $$ \omega \in A \vee \omega \not \in A \, \forall \omega \in \Omega $$                                          	|
| Событие $A$ влечёт событие $B$ («если $A$, то $B$», $A \Rightarrow B$) 	|                                          $$ A \subseteq B \Leftrightarrow \forall \omega \in A, \omega \in B $$                                          	|
|                 Событие $A$ не произошло: $\overline A$                	|                              Дополнение к множеству $A$ $$ \overline A = \{ \omega \in \Omega \such \omega \not \in A \} $$                              	|
|          Произошли все события $A_i$ в одном акте эксперимента         	|                       Пересечение множеств $A_i$ $$ \bigcap_i A_i = \{ \omega \in \Omega \such \forall i \,\, \omega \in A_i \} $$                       	|
|                 Произошло хотя бы одно событие из $A_i$                	|                          Объединение множеств $$ \bigcup_i A_i = \{ \omega \in \Omega \such \exists i \,\, \omega \in A_i \} $$                          	|
|           Произошло событие $A$, но не произошло событие $B$           	|                        Разность множеств $$ A \setminus B = \{ \omega \in \Omega \such \omega \in A \wedge \omega \not \in B \} $$                       	|
|         Либо произошло событие $A$, либо произошло событие $B$         	| Симметрическая разность множеств $$ A \symdif B = \{ \omega \in \Omega \such \omega \in A \xor \omega \not \in B \} = (A \cup B) \setminus (A \cap B) $$ 	|

Соотношение событий и операций над множествами

:::

:::{.callout-tip}
### Свойства операций над множествами

Вспомним кратко свойства операций над множествами, чтобы не листать книжку.

1. Коммутативность <br> $A \cup B = B \cup A$ <br> $A \cap B = B \cap A$
2. Ассоциативность <br> $(A \cup B) \cup C = A \cup (B \cup C)$ <br> $(A \cap B) \cap C = A \cap (B \cap C)$
3. Дистрибутивность <br> $(A \cup B) \cap C = (A \cap C) \cup (A \cap B)$ <br> $(A \cap B) \cup C = (A \cup C) \cap (A \cup B)$
4. Формулы двойственности <br> $\overline{A \cap B} = \overline A \cup \overline B$ ; $\overline{A \cup B} = \overline A \cap \overline B$ <br> $\displaystyle \overline{\bigcup_i A_i} = \bigcap_i \overline{A_i}$; $\displaystyle \overline{\bigcap_i A_i} = \bigcup_i \overline{A_i}$
5. Свойства включения <br> $A \subseteq B \wedge B \subseteq C \Rightarrow A \subseteq C$ <br> $\emptyset \subset A \subset \Omega$ <br> $A \subset B \Rightarrow \cases{A \cap B = A \\ A \cup B = B}$
6. Двойное дополнение <br> $\overline{(\overline A)} = A$

:::


## Предел последовательности множеств {#prob-lim-set}

:::{.lab-senior}
:::

Мы движемся всё ещё движемся к построению вероятности, однако давайте на секунду остановимся и задумаемся вот на чем: когда мы построим вероятность, нам необходимо будет исследовать её аналитические свойства, чтобы понять, как она работает. Исследование любых аналитических свойств предполагает, что мы умеем считать пределы последовательностей. Так как вероятность будет стоять на множествах --- в частности, событиях --- нам потребуются пределы последовательностей множеств. На данный момент совершенно не ясно, как их считать. Озаботимся этим вопросом.

Сходу неясно, как посчитать предел последовательности множеств, но из матана мы знаем, как считать предела числовых последовательностей. Можно ли как-то на элементах множеств создать некоторую числовую последовательность, логически отражающую свойства множеств?


### Индикаторная функция {#prob-indic-function}

:::{.lab-guru}
:::

Да. Сделаем мы это исходя из весьма простого соображения.

:::{#def-indic-funciton}
Функция $\chi_A(\omega): \Omega \to \{0, 1\}$ называется **индикаторной функцией множества $A$**, если она задана следующим образом:

$$
\chi_A(\omega) = \cases{
1, \, \omega \in A \\
0, \, \omega \not \in A
}
$$

:::

Будет ли такая функция отражать свойства множеств? Да, так как она обладает следующими свойствами:


1. $A \subseteq B \Leftrightarrow \chi_A(\omega) \leq \chi_B(\omega), \, \forall \omega \in \Omega$
2. $A = B \Leftrightarrow \chi_A(\omega) = \chi_B(\omega), \, \forall \omega \in \Omega$
3. $\chi_{\overline A} (\omega) = 1 - \chi_A(\omega), \, \forall \omega \in \Omega$
4. $\chi_{A \cup B}(\omega) = \max \big( \chi_A(\omega), \chi_B(\omega) \big), \, \forall \omega \in \Omega$
5. $\chi_{A \cap B}(\omega) = \min \big( \chi_A(\omega), \chi_B(\omega) \big), \, \forall \omega \in \Omega$

***

Как индикаторная функция поможет нам в определении предела последовательности множеств?

Пусть есть последовательность множеств $A_1, A_2, \ldots, A_n, \ldots$ $(A_k \subseteq \Omega)$.

1. Будем говорить, что существует предел последовательности множеств $\lim_{n \to \infty} A_n$, если существует предел последовательности индикаторных функций множеств этой последовательности $\lim_{n \to \infty} \chi_{A_n}(\omega)$.
2. Это равносильно тому, что для любого $\omega$ либо индикаторная функция $\chi_{A_n}(\omega) = 1$, начиная с некоторого номера $n_0$, либо индикаторная функция $\chi_{A_n}(\omega) = 0$, начиная с некоторого номера $\tilde n_0$.
3. Из этого следует, что предел последовательности индикаторных функций $\lim_{n \to \infty} \chi_{A_n} (\omega)$ будет равен либо нулю, либо единице.
4. Следовательно, будет является индикаторной функцией некоторого множества $A$.
5. Это множество $A$ мы по определению назовём **пределом последовательности множеств** $(A_n)_{n=1}^\infty$.

То же самое рассуждение, но без слов:

$$
\begin{split}
&\exists \lim_{n \to \infty} A_n \overset{\circled{1}}{\Leftarrow}
\forall \omega \in \Omega \, \exists \lim_{n \to \infty} \chi_{A_n} (\omega) \overset{\circled{2}}{\Leftrightarrow} \\
&\forall \omega \in \Omega \,\, 
\left [ 
\begin{aligned} 
\chi_{A_n} (\omega) &= 1, \forall n > n_0 \\
\chi_{A_n} (\omega) &= 0, \forall n > \tilde n_0 \end{aligned}
\right.
\overset{\circled{3}}{\Rightarrow} \\
& \lim_{n \to \infty} \chi_{A_n} (\omega) = 
\left [ 
\begin{aligned} 
&1 \\ 
&0 
\end{aligned} 
\right. \overset{\circled{4}}\Rightarrow 
\chi_{A_n}(\omega) \overset{\circled{5}}{\Rightarrow }
A \defin \lim_{n \to \infty} A_n
\end{split}
$$

:::{#def-lim-setseq}
Пределом последовательности множеств $(A_n)_{n=1}^\infty$ называется множество $A$, индикаторная функция которого является пределом индикаторных функций множеств данной последовательности:

$$
A \defin \lim_{n \to \infty} A_n \Leftrightarrow \chi_A (\omega) = \lim_{n \to \infty} \chi_{A_n} (\omega)
$$
:::


### Вычисление пределов последовательностей множеств {#prob-get-set-lims}

:::{.lab-senior}
:::

Индикаторная функция --- это, конечно, хорошо. Как минимум, она позволила нам дать определение предела последовательности множеств. Однако обращаться к ней каждый раз для вычисления необходимого предела не очень удобно --- хотелось бы оставаться в процессе нахождения предела в рамках операций над множествами.

Из математического анализа известно(HREF), что есть числовая последовательность имеет предел, что они имеет верхний и нижний пределы, которые совпадают, то есть

$$
(x_n)_{n=1}^\infty \subset \setR, \,\, \exists \, x = \lim_{n \to \infty} x_n \Leftrightarrow \limsup_{n \to \infty} x_n = \liminf_{n \to \infty} x_n = x
$$

* *Верхний предел* --- максимальная из всех предельных точек.

$$
\limsup_{n \to \infty} x_n = \inf_{n = 1,2,\ldots} \sup_{k = n,n+1,\ldots} x_n
$$

* *Нижний предел* --- минимальная из всех предельных точек.

$$
\liminf_{n \to \infty} x_n = \sup_{n = 1,2,\ldots}\inf_{k = n,n+1,\ldots} x_n
$$

Это условие является необходимым и достаточным для того, чтобы последовательность сходилась.

Попробуем перенести эти размышления на операции со множествами. Заметим, что взятие максимума множеств эквивалентно операции объединения 

$$
\bigcup_k \Leftrightarrow \max_k,
$$

а взятие минимума --- операции пересечения

$$
\bigcap_k \Leftrightarrow \min_k.
$$

Тогда можно дать следующие определения.

:::{#def-limsup-setseq}

Множество $\displaystyle \bigcap_{n=1}^\infty \bigcup_{k = n}^\infty A_k$ называется **верхним пределом** последовательности множеств $(A_n)_{n=1}^\infty$.

$$
\bigcap_{n=1}^\infty \bigcup_{k = n}^\infty A_k \defin \limsup_{n \to \infty} A_n
$$
:::

:::{#def-liminf-setseq}
Множество $\displaystyle \bigcup_{n=1}^\infty \bigcap_{k = n}^\infty A_k$ называется **нижним пределом** последовательности множеств $(A_n)_{n=1}^\infty$.

$$
\bigcup_{n=1}^\infty \bigcap_{k = n}^\infty A_k \defin \liminf_{n \to \infty} A_n
$$
:::

Довольно громоздкие конструкции... Давайте попробуем понять, что они обозначают по сути.

В первом случае (@def-limsup-setseq):

$$
\omega \in \bigcap_{n=1}^\infty \bigcup_{k=n}^\infty A_k \Leftrightarrow \forall n = 1, 2, \ldots \exists k \geq n : \omega \in A_k \Leftrightarrow \exists k_1, k_2, \ldots, k_n \to \infty : \omega \in A_{k_n}, \forall n = 1, 2, \ldots
$$

Во втором случае (@def-liminf-setseq)

$$
\omega \in \bigcup_{n=1}^\infty \bigcap_{k=n}^\infty A_k \Leftrightarrow \exists n: \forall k \geq n \,\, \omega \in A_k \Leftrightarrow \omega \in A_n, A_{n+1}, \ldots
$$


$$
\limsup_{n \to \infty} A_n \supseteq \liminf_{n \to \infty} A_n,
$$

что ясно, если в качестве последовательности $k_n$ для верхнего предела взять $k_n = \{ n, n+1, n+2, \ldots \}$.

Из формул двойственности следует, что 

$$
\overline{\bigcup_{n=1}^\infty \bigcap_{k = n}^\infty A_k} = \bigcap_{n=1}^\infty \bigcup_{k = n}^\infty \overline{A_k} \Leftrightarrow \overline{ \liminf_{n \to \infty} A_n } = \limsup_{n \to \infty} \overline{ A_n }
$$

Также имеем, что

$$
\exists \, A = \lim_{n \to \infty} A_n \Leftarrow \limsup_{n \to \infty} A_n = \liminf_{n \to \infty} A_n \defin A
$$

Матан: всякая монотонная и ограниченная сверху и снизу последовательность имеет предел.

:::{#lem-limunion-setseq}
Пусть $A_1 \subseteq A_2 \subseteq \ldots \subseteq A_n \subseteq \ldots \subseteq \Omega$ --- монотонная неубывающая последовательность $(A_n)_{n=1}^\infty$. Тогда такая последовательность имеет предел, равный общему объединению множеств, входящих в последовательность:

$$
\lim_{n \to \infty} A_n = \bigcup_{n=1}^\infty A_n
$$
:::

:::{.proof}
Необходимо доказать, что

$$
\limsup_{n \to \infty} A_n \overset{\circled{1}}{=} \liminf_{n \to \infty} A_n \overset{\circled{2}}{=} \bigcup_{n=1}^\infty A_n
$$

Равенство $\circled{1}$ утверждает, что существует предел, а равенство $\circled{2}$ утверждает, что этот предел равен общему объединению множеств. Здесь, за самом деле, скрывается и третье равенство $\limsup_{n \to \infty} A_n \overset{\circled{3}}{=} \bigcup_{n=1}^\infty A_n$, однако для доказательства цепочки равенств достаточно доказать *любые два из трёх* --- справедливость оставшегося будет следовать из транзитивности равенства. Докажем равенства $\circled{3}$ и $\circled{2}$.

Для равенства $\circled{3}$ имеем, что

$$
\limsup_{n \to \infty} A_n \defin \bigcap_{n=1}^\infty \bigcup_{k=n}^\infty A_k \overset{?}{=} \bigcup_{n=1}^\infty A_n
$$

Необходимо показать совпадение множеств $\bigcap_{n=1}^\infty \bigcap_{k=n}^\infty A_k$ и $\bigcup_{n=1}^\infty A_n$. Чтобы это сделать, необходимо показать, что любой элемент из левого множества принадлежит правому, и наоборот.

Пусть $\displaystyle \omega \in \bigcap_{n=1}^\infty \bigcup_{k=n}^\infty A_k$. Тогда:

$$
\omega \in \bigcap_{n=1}^\infty \bigcup_{k=n}^\infty A_k \Leftrightarrow \forall n \, \exists k \geq n : \omega \in A_{k_n} \Rightarrow \omega \in \bigcup_{n=1}^\infty A_n
$$

Пусть $\displaystyle \omega \in \bigcup_{n=1}^\infty A_n$. Тогда:

$$
\begin{split}
&\omega \in \bigcup_{n=1}^\infty A_n \Leftrightarrow \exists n_0 : \omega \in A_{n_0} \subseteq A_{n_0+1} \subseteq \ldots \subseteq A_{n_0+m} \subseteq \ldots \Rightarrow \\
&\omega \in A_{n_0+m} \forall m \geq 0 \Rightarrow \forall m = 1, 2, \ldots \, \exists k \geq n: \omega \in A_k, k = \cases{n_0, \, n \leq n_0 \\ n_0 + m, \, n > n_0, n = n_0 + m, m > 0} \Rightarrow \\
&\omega \in \bigcap_{n=1}^\infty \bigcup_{k=n}^\infty A_k
\end{split}
$$

Для равенства $\circled{2}$ сразу имеем:

$$
\liminf_{n \to \infty} A_n = \bigcup_{n=1}^\infty \bigcap_{n=1}^\infty A_k = \bigcup_{n=1}^\infty A_n,
$$

так как $\displaystyle A_1 \subseteq A_2 \subseteq \ldots \Rightarrow \bigcap_{k=n}^\infty A_k = A_n$.

**Q.E.D.**
:::


:::{#lem-limintersection-setseq}
[[Дуальная к @lem-limunion-setseq]] Пусть $\Omega \supseteq A_1 \supseteq A_2 \supseteq \ldots \subseteq A_n \supseteq \ldots$ --- монотонная невозрастающая последовательность $(A_n)_{n=1}^\infty$. Тогда такая последовательность имеет предел, равный общему пересечению множеств, входящих в последовательность:

$$
\lim_{n \to \infty} A_n = \bigcap_{n=1}^\infty A_n
$$
:::

:::{.proof}
Докажем, воспользовавшись формулами двойственности:

$$
\lim_{n \to \infty} A_n \overset{\circled{✓}}{=} \lim_{n \to \infty} \overline{A_n} = \bigcup_{n=1}^\infty \overline{A_n} = \bigcap_{n=1}^\infty A_n
$$
**Q.E.D.**
:::

:::{.remark}
Сделаем замечание, относительно равенства $\circled{✓}$.
:::


## $\sigma$-алгебра событий

Вся кропотливая деятельность, связанная со множествами, была обусловлена необходимостью построения конструкции вероятности. Напомним ещё раз себе, что мы хотим для событий $A$ ($A \subseteq \Omega$) «построить» вероятность $\prob(A)$. «Построить» значит задать функцию, которая подмножеству сопоставляет некоторое число.

Задание функции начинается с задания её **области определения** --- где вообще должна существовать та функция, которую мы желаем построить? Есть несколько соображений здравого смысла относительно области определения вероятности.

1. Очевидно, что область определения вероятности (по определению) должна состоять из таких событий $A$, для которых существует $\prob(A)$:

$$
\mathcal D(\prob(A)) \defin \{ A \subseteq \Omega \such \exists \prob(A) \}
$$

2. Если существует вероятность события $A$, то должна существовать и вероятность обратного события $\overline{A}$:

$$
\exists \prob(A) \Rightarrow \exists \prob(\overline{A})
$$

3. Если существуют вероятности событий $A$ и $B$, то должны существовать вероятности событий, состоящих из их объединения, пересечения и всех других разумных операций для множествами --- то есть операции над событиями как множествами не должны выводить из области определения вероятности:

$$
\exists \prob(A), \prob(B) \Rightarrow \exists \prob(A \cup B), \prob(A \cap B), \prob(A \setminus B), \ldots
$$

Таких требований можно придумать достаточно много, и необходимо выбрать минимальный комплекс требования, чтобы избежать переопределения понятий. В частности, нужно ли нам перечислять в пункте (3) все операции, если $A \cap B = \overline{\overline{A} \cup \overline{B}}$ и $A \cup B = \overline{\overline{A} \cap \overline{B}}$?

:::{#def-algF}
Система $\Fcal$ подмножеств $\Omega$ называется **алгеброй** подмножеств, если она замкнута относительно операций дополнения и объединения.

$$
\begin{aligned}
&A \in \Fcal \Rightarrow \overline{A} \in \Fcal &&& \circled{\Fcal1} \\
&A,B \in \Fcal \Rightarrow A \cup B \in \Fcal &&& \circled{\Fcal2}
\end{aligned}
$$
:::

:::{#cor-intersection-algF}
[Из требования $\circled{\Fcal2}$]

$\Fcal$ также замкнута относительно пересечения множеств:

$$
A \cap B = \overline{\overline{A} \cup \overline{B}} \in \Fcal,
$$

так как $\overline{A}, \overline{B} \in \Fcal \Rightarrow \overline{A} \cup \overline{B} \in \Fcal \Rightarrow \overline{\overline{A} \cup \overline{B}} \in \Fcal$.
:::

:::{#cor-emptyomega-alfF}
[Из требования $\circled{\Fcal2}$]

Пустое множество $\emptyset$ и $\Omega$ также принадлежат $\Fcal$:

$$
A \in \Fcal \Rightarrow 
\left [ 
\begin{aligned}
A &= \emptyset \Rightarrow \overline{A} = \Omega \in \Fcal \\
A &= \Omega \Rightarrow \overline{A} = \emptyset \in \Fcal \\
A &\neq \emptyset, \Omega, \, A \cup \overline{A} = \Omega \in \Fcal, \, A \cap \overline{A} = \emptyset \in \Fcal
\end{aligned}
\right.
$$
:::

:::{.remark}
Отметим также две замечательные алгебры:

* наименьшей возможной алгеброй является множество $\Fcal_\min = \{ \emptyset, \Omega \}$ и $\Fcal_\min \subset \Fcal \,\, \forall \Fcal$
* наибольшей возможной алгеброй является множество $\Fcal_\max = 2^\Omega$ и $\Fcal \subset \Fcal_\max \,\, \forall \Fcal$

:::

:::{#cor-finiteunion-algF}
Из требования $\circled{\Fcal2}$ также следует, что

$$
A_n \in \Fcal \Rightarrow \bigcup_{k=1}^n A_k \in \Fcal \,\, \forall n < \infty, \, A_k \in \Fcal
$$
:::

Однако из $\circled{\Fcal2}$ *не следует*, что

$$
\circled{\Fcal2} \not \Rightarrow \bigcup_{k=1}^\infty A_k \in \Fcal, \,\, A_1, A_2, \ldots \in \Fcal
$${#eq-infty-union-algF}

Для задания вероятности нам необходимо, чтобы счетное объединение множеств, принадлежащих $\Fcal$ также принадлежало $\Fcal$, то есть чтобы [следствие @eq-infty-union-algF] выполнялось. Отсутствие принадлежности счетного объединения как следствия принадлежности конечного объединения требует дополнения определения данным требованием.

:::{#def-sigma-algF}
Систем $\Fcal$ подмножеств $\Omega$ называется **$\sigma$-алгеброй**, есл она замкнута относительно операций дополнения и *конечного и счётного* объединения.

$$
\begin{aligned}
&A \in \Fcal \Rightarrow \overline{A} \in \Fcal &&& \circled{\Fcal1} \\
&A,B \in \Fcal \Rightarrow A \cup B \in \Fcal &&& \circled{\Fcal2} \\
&A_1, A_2, \ldots \in \Fcal \Rightarrow \bigcup_{n=1}^\infty A_n \in \Fcal &&& \circled{\Fcal3}
\end{aligned}
$$
:::

Необходимость отдельно налагать условие $\circled{\Fcal3}$ возникает из-за того, что предельный переход в общем случае можем менять свойства объекта (см. @eq-infty-union-algF).

:::{#cor-sigma-algF-algF}
Очевидно, что если $\Fcal$ является $\sigma$-алгеброй, то $\Fcal$ является алгеброй, так как

$$
\circled{\Fcal1} \wedge \circled{\Fcal2} \wedge \circled{\Fcal3} \Rightarrow \circled{\Fcal1} \wedge \circled{\Fcal2}
$$
:::

:::{#prp-finite-algF-sigma-algF}
Если $\Omega$ конечно, то любая алгебра $\Fcal$ подмножеств $\Omega$ является $\sigma$-алгеброй подмножеств $\Omega$.
:::

Зачем мы возвели на множестве $\Omega$ какую-то конструкцию под названием $\sigma$-алгебра $\Fcal$? Именно $\Fcal$ будет являться областью определения вероятности $\prob (A)$.


## Система аксиом вероятности {#prob-kolmogorov-axioms}

Окей, мы, слава святому рандому, определились с тем, как устроена область определения вероятности $\mathcal{D}(\prob(A)) = \Fcal$. Может хоть теперь мы уже наконец-то сможем задать вероятность?

Да, мы критически близки к этому моменту. Откатимся немного назад и вспомним, с чего мы начали.

* Мы хотели задать вероятность как относительную частоту $\displaystyle \prob (A) \approx \frac{n(A)}{n}$, но [выяснили](#prob-not-freq), что так у нас сделать не получится.
* Мы определили множество элементарных исходов $\Omega$ и $\sigma$-алгебру подмножеств $\Fcal$ на нём и заявили, что она будет являться область определения вероятности.
* Как же, собственно, мы должны задать саму вероятность как функцию?

Всё-таки нам хотелось бы, чтобы вероятность была идеализированной частотой, то есть отражала её свойства, а значит сразу возникают довольно естественные требования к определению вероятности:

* Во-первых, вероятность должна быть «зажата» между $0$ и $1$:

$$
0 \leq \prob(A) \leq 1
$$

* Во-вторых, вероятность обратного события должна быть равна разности единицы и вероятности прямого события:

$$
\prob(\overline{A}) = 1 - \prob(A)
$$

* В-третьих, если события *несовместны* --- $A \cap B = \emptyset$, то есть $\nexists \omega : \omega \in A \cap B$, то

$$
\prob (A \cup B) = \prob(A) + \prob(B)
$$

или можно записать по-другому[^sqcap]

[^sqcap]: Здесь используется знак дизъюнктного объединения, который обозначает объединение непересекающихся множеств: $A \sqcup B = A \cup B, \,\, A \cap B = \emptyset$.

$$
\prob (A \sqcup B) = \prob(A) + \prob(B)
$$

Последнее требование похоже на $f(x + y) = f(x) + f(y)$ --- это свойство функции называется *аддитивностью*, то есть мы хотим, чтобы вероятность была аддитивной конструкцией.

* В-четвертых, логично потребовать, чтобы $\prob (\Omega) = 1$ и $\prob (\emptyset) = 0$.

Вновь можно выдвинуть довольно много требований и вновь нам надо определиться с тем, каков будет минимальный их набор, обеспечивающий все нам необходимые. Такой набор требований был предложен А. Н. Колмогоровым [@kolmogorov1974] и составляет **систему аксиом вероятности [Колмогорова]**.

:::{#prp-kolmogorov-axioms}
**Cистема аксиом вероятности [Колмогорова]**

Пусть $\Omega$ --- множестве элементарных исходов случайного эксперимента, $\Fcal$ --- множество подмножеств $\Omega$, а $\prob$ --- вероятность.

$\circled{\text{A0}}$ Множество событий $\Fcal$ является $\sigma$-алгеброй.

$\circled{\text{A1}}$ Любому событию $A$ из $\Fcal$ ставится в соответствие неотрицательное действительное число $\prob(A)$, называемое вероятностью события $A$.

$\circled{\text{A2}}$ (*Аксиома счетной аддитивности*) Если события $A_1$, $A_2$, $\ldots$ не пересекаются, то вероятность события, являющегося их объединением, равна сумме вероятностей этих событий.

$\circled{\text{A3}}$ Вероятность множества элементарных исходов равна единице.

$$
\begin{aligned}
& \Fcal = \{ A \subseteq \Omega \such \exists \, \prob(A) \} \text{ есть } \sigma \text{-алгебра} &&& \circled{\text{A0}} \\ 
& \forall A \in \Fcal \,\, \exists \prob(A) \geq 0, \prob(A) \in \setR  &&& \circled{\text{A1}}\\
& \forall A_1, A_2, \ldots \in \Fcal : A_i \cap A_j = \emptyset, i \neq j \,\, \prob \Big( \bigsqcup_{k=1}^\infty A_k \Big) = \sum_{k=1}^\infty \prob(A_k) &&& \circled{\text{A2}} \\
& \prob(\Omega) = 1 &&& \circled{\text{A3}}
\end{aligned}
$$
:::

Мы отмечали, что вероятность --- это мера множества. Теперь, учитывая аксиому $\circled{\text{A2}}$ мы можем сказать, что **вероятность --- это счётно-аддитивная мера**.

Из аксиом Колмоголова получается ряд следствий.

:::{#cor-prob-emptyset}
Вероятность пустого множества равна нулю.

$$
\prob (\emptyset) = 0
$$
::: 

:::{.proof}
Займемся высокоинтеллектуальной деятельностью.

Пусть $A_1 = A_2 = \ldots = A_n = \ldots = \emptyset$. Тогда $\emptyset \in \Fcal \Rightarrow \exists \, \prob(A_k) = p \geq 0$. Очевидно, что $\bigcup_{n=1}^\infty A_n = \emptyset$, так как если $\omega \in \bigcup_{n=1}^\infty A_n$, то $\omega \in A_n$, но $A_n = \emptyset$. Ясно, что $A_i \cap A_j = \emptyset \,\, \forall i, j$, значит можно применить аксиому $\circled{\text{A2}}$. По аксиоме $\circled{\text{A2}}$:

$$
p = \prob(\emptyset) = \prob \Big( \bigsqcup_{n=1}^\infty A_n \Big) = \sum_{n=1}^\infty \prob(A_n) = \sum_{i=1}^\infty p
$$

Из выражения $p = \sum_{i=1}^\infty p$ следует единственно возможное решение $p = 0$.
:::

:::{#cor-finite-add}
[*Конечная аддитивность*]

$$
\begin{aligned}
&\prob (A \sqcup B) = \prob(A) + \prob(B) &&& \circled{\tilde{\text{A2}}}
\end{aligned}
$$
:::

:::{.proof}
Пусть $A_1 = A$, $A_2 = B$, $A_3 = A_4 = \ldots = A_n \ldots = \emptyset$.

$$
A \sqcup B = \bigsqcup_{k=1}^\infty A_k \overset{\circled{\text{A2}}}{\Rightarrow} \prob(A \sqcup B) = \sum_{k=1}^\infty \prob(A_k) = \prob(A) + \prob(B)
$$

::::

Иногда [следствие @cor-finite-add] вводится в систему аксиом вероятности в качестве отдельной аксиомы --- здесь она обозначена как $\circled{\tilde{\text{A2}}}$. Однако, как мы видим, свойство конечной аддитивности является следствием аксиомы счётной аддитивности.

:::{#cor-compl-event-prob}
[*Вероятность обратного события*]

$$
\prob(\overline{A}) = 1 - \prob(A)
$$
:::

:::{.proof}
$$
\Omega = A \sqcup \overline{A} \overset{\circled{\tilde{\text{A2}}}}{\underset{ \circled{\text{A3}}}{\Rightarrow}} 1 = \prob(A) + \prob(\overline{A}) \Rightarrow \prob(\overline{A}) = 1 - \prob(A)
$$
:::


:::{#cor-ord-prob}
Если $A, B \in \Fcal$ и $A \subseteq B$, то $\prob (A) \leq \prob(B)$.
:::

:::{.proof}
$$
B = A \sqcup (B \setminus A)
$$

$$
(B \setminus A) = B \cap \overline{A} \in \Fcal \Rightarrow \prob (B) = \prob(A) + \underset{\geq 0}{\prob(B \setminus A)} \geq \prob(A)
$$
:::





```{=html}
<script type="text/javascript" src="./js/chapter.js"></script>
```
