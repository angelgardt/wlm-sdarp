# Тестирование статистических гипотез {#prob-hyptesting}

{{< include other/_symbols.qmd >}}

```{r opts, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, error=FALSE}
knitr::opts_chunk$set(echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE, error=FALSE)
```

:::{.intro}
Вступление
:::



## Закономерности и различия {#prob-hyptesting-hypotheses-differences}

:::{.lab-junior}
:::



## Гипотезы и данные {#prob-hyptesting-hypotheses-data}

:::{.lab-junior}
:::



## Виды гипотез {#prob-hyptesting-hypotheses}

:::{.lab-junior}
:::

**Гипотеза** ($H$, от англ. или лат. _**h**ypothesis_) --- это некоторое предположение, которое подлежит проверке на основе результатов наблюдений.

Всего можно выделить три вида гипотез --- *теоретические*, *эмпирические* и *статистические*.

* **Теоретическая гипотеза** формулируется в терминах изучаемых конструктов. 
* **Эмпирическая гипотеза** формулируется в терминах переменных, включенных в дизайн исследования.
* **Статистическая гипотеза** формулируется в терминах параметров генеральной совокупности. про данные (что мы получили в данный конкретный момент, собрав вот эти конкретные данные).

Статистические гипотезы в свою очередь делятся на два вида --- *простые* и *сложные*.

* **Простая гипотеза** представляет собой предположение, которое включает в себя однозначно сформулированное утверждение. Например, величина параметра генеральной совокупности соответствует некоторому строго заданному значению: $H : \theta = \theta_0$, где $\theta$ --- величина параметра, а $\theta_0$ --- заранее заданное значение. Другой вариант --- две генеральные совокупности обладают одним и тем же значением параметра: $H : \theta_1 = \theta_2$.
* **Сложная гипотеза** предполагает множественность вариантов значения параметра, которые укладываются в рамки проверяемого предположения. Например, $H : \theta > \theta_0$ или $H : \theta_1 \neq \theta_2$.

В ходе самого процесса тестирования гипотез выделяют *нулевую* и *альтернативную* гипотезы.

* **Нулевая гипотеза** ($H_0$) --- это гипотеза, которую мы и будем проверять в ходе тестирования. Чтобы упростить процесс тестирования гипотезы, стараются максимально упростить и саму гипотезу --- практически всегда нулевая гипотеза формулируется как *простая гипотеза*.
* **Альтернативная гипотеза** ($H_1$) --- это гипотеза, выдвигаемая в противовес нулевой. Так как нулевая гипотеза чаще всего является простой гипотезой, а значит предполагает конкретное значение параметра, то альтернативная неизбежно получается *сложной гипотезой*.


### Нулевая гипотеза {#prob-hyptesting-null-hypothesis}

:::{.lab-junior}
:::

Вариантов сформулировать нулевую гипотезу так, чтобы она была простой, всего два:

1. $H_0 : \theta = \theta_0$,
1. $H_0 : \theta_1 = \theta_2$.

Как нетрудно заметить, оба варианта *предполагают отсутствие различий*:

1. в первом случае параметр *не отличается* от некоторого заданного значения,
2. во втором параметры двух генеральных совокупностей *не отличаются* друг от друга.

:::{.callout-note .save-font-size appearance="minimal"}
Таким образом, **нулевая гипотеза --- это гипотеза об отсутствии различий**, а следовательно, об отсутствии закономерности.
:::

### Альтернативная гипотеза {#prob-hyptesting-alt-hypothesis}

:::{.lab-junior}
:::

С альтернативной гипотезой дела обстоят интереснее. Факт того, что альтернативная гипотеза является сложной, позволяет выдвинуть *три* варианта альтернативной гипотезы к нулевой гипотезе (@tbl-alt-hyp).

* Нас может интересовать полностью противоположная нулевой гипотезе ситуация. Тогда
  * для нулевой гипотезы $H_0 : \theta = \theta_0$ альтернативная гипотеза будет формулироваться как $H_1 : \theta \neq \theta_0$,
  * для нулевой гипотезы $H_0 : \theta_1 = \theta_2$ --- соответственно как $H_1 : \theta_1 \neq \theta_2$.

Ситуация $\theta \neq \theta_0$, конечно же, включается в себя и ситуацию $\theta < \theta_0$, и ситуацию $\theta > \theta_0$, то есть в качестве альтернативы мы рассматриваем *две стороны* возможных различий. Аналогично $\theta_1 \neq \theta_2 \Leftrightarrow \theta_1 < \theta_2 \wedge \theta_1 > \theta_2$[^logic_two_side].

:::{.callout-note .save-font-size appearance="minimal"}
Такие альтернативные гипотезы называются **двусторонними (two-sided hypothesis, two-tailed test)**.
:::

Они описывают ситуацию, когда различия есть, но нам не важно, куда они направлены --- (1) больше или меньше параметр $\theta$ заданного значения $\theta_0$ или (2) какой из параметров $\theta_1$ и $\theta_2$ больше другого.

[^logic_two_side]: Здесь использованы логические операторы: эквивалентность (равносильность, $\Leftrightarrow$) и конъюнкция (логическое И, $\wedge$). Подробнее см. главу «[Логика и алгебра логики](math-logic.qmd)».

* Однако нам могут быть интересны *направленные* альтернативные гипотезы.
  * Пусть для нас в рамках исследования закономерностью является то, что значение параметра будет *больше* некоторого заранее заданного значения. Тогда для нулевой гипотезы $H_0 : \theta = \theta_0$ альтернативная гипотеза будет формулирована как $H_1 : \theta > \theta_0$,
  * Или же с теоретических позиций мы решаем, что закономерность присутствует в случае, когда параметр первой генеральной совокупности *меньше* параметра второй генеральной совокупности. Тогда для нулевой гипотезы $H_0 : \theta_1 = \theta_2$ альтернативная будет выглядеть так: $H_1 : \theta_1 < \theta_2$.

Мы можем «направить» альтернативные гипотезы и в обратную сторону, если это согласуется с теоретическими основаниями --- $H_1 : \theta < \theta_0$ и $H_1 : \theta_1 > \theta_2$ соответственно.

:::{.callout-note .save-font-size appearance="minimal"}
Такие альтернативные гипотезы называются **односторонними (one-sided hypothesis, one-tailed test)**.
:::

:::{.callout-note .save-font-size appearance="minimal"}
Если нас интересует ситуация «меньше», то гипотеза называется **левосторонней (left-tailed test)**.
:::

:::{.callout-note .save-font-size appearance="minimal"}
Если же нас интересует ситуация «больше», то гипотеза будет **правосторонней (right-tailed test)**.
:::

::: {#tbl-alt-hyp}

|                                             	| $H_0 : \theta = \theta_0$    	| $H_0 : \theta_1 = \theta_2$    	|
|---------------------------------------------	|------------------------------	|--------------------------------	|
| Двусторонняя альтернатива                   	| $H_1 : \theta \neq \theta_0$ 	| $H_1 : \theta_1 \neq \theta_2$ 	|
| Односторонняя альтернатива (левосторонняя)  	| $H_1 : \theta < \theta_0$    	| $H_1 : \theta_1 < \theta_2$    	|
| Односторонняя альтернатива (правосторонняя) 	| $H_1 : \theta > \theta_0$    	| $H_1 : \theta_1 > \theta_2$    	|

Альтернативные гипотезы: односторонние и двусторонние альтернативы.
:::

На что будет влиять «сторонность» гипотезы? И как выбрать, какая нам нужна в конкретном исследовании? Мы обязательно ответим на эти вопросы, но чуть позже --- пока что нам не хватает знаний, чтобы пронаблюдать возможные последствия.



## Возможные результаты проверки гипотез {#prob-hyptesting-results}

:::{.lab-junior}
:::

Изучая в исследовании какую-либо закономерность, мы достоверно не знаем, существует ли она в реальном мире. *В реальном мире* в данном контексте означает *на уровне генеральных совокупностей*. Почему мы не знаем --- и не можем знать --- об этом достоверно? Причина такого положения дел нам хорошо известна: генеральная совокупность недоступна для наблюдения в полном объеме. Тем не менее, в мире ~~идей~~ генеральных совокупностей закономерность **может существовать**, а **может и не существовать**.

:::{.quote .small}
--- Ну, тоже мне, великое умозаключение! Это же предельно очевидно!<br>
--- Да, но давайте посмотрим, что получается дальше.
:::

Имея дело с выборкой, мы вспоминаем о двух ключевых характеристиках статистических данных --- их **неопределенности** и **вариативности**[^statdata]. В силу этих характеристик мы можем на отдельной выборке **либо обнаружить** интересующую нас закономерность, **либо не обнаружить**.

[^statdata]: Если вы успели подзабыть, что это такое, посмотрите [этот раздел](desc-statintro.qmd#desc-statintro-statdata).

:::{.quote .small}
--- Ну, ясно же! Если закономерность есть, то мы её обнаружим, если нет --- то не обнаружим!<br>
--- Ах, если бы это было так…
:::

Поскольку ни одно исследование не является идеальным, мы можем обнаружить или не обнаружить исследуемую закономерность как в ситуации наличия её в генеральной совокупности, так и в ситуации отсутствия таковой.

В качестве нулевой гипотезы мы выдвигаем предположение о том, что изучаемая закономерность отсутствует --- так мы упрощаем нашу нулевую гипотезу. Пусть $H_0$ обозначает, что предположение об отсутствии закономерности справедливо, а $H_1$ --- что это предположение не справедливо. Иначе говоря, $H_0$ обозначает ситуацию, что **закономерности в генеральной совокупности нет**, а $H_1$ --- что **закономерность в генеральной совокупности есть**.

На основании данных, собранных на отдельной выборке, мы можем либо не отклонить наше предположение (нулевую гипотезу), то есть **не обнаружить закономерность**, либо отклонить исходное предположение (нулевую гипотезу), то есть **обнаружить закономерность**. Обозначим ситуацию, когда мы *не обнаружили* закономерность как $\hat H_0$, а ситуацию, когда мы *обнаружили закономерность*, как $\hat H_1$. Поскольку сейчас мы работаем с выборкой, то ашки у нас в шляпках.

Тогда при тестировании статистических гипотез возможны следующие ситуации (@tbl-stattest-situations):

:::{#tbl-stattest-situations}

|  | $H_0$ | $H_1$ |
|:---:|:---:|:---:|
| $\hat H_0$ | **Ситуация 1**<br> ✓ | **Ситуация 2**<br> Ошибка II рода (Type II Error) |
| $\hat H_1$ | **Ситуация 3**<br> Ошибка I рода (Type I Error) | **Ситуация 4**<br> ✓ |

Ситуации, возникающие при тестировании статистических гипотез
:::

Ситуации 1 и 4 нас полностью устраивают:

* Ситуация 1: не было закономерности, мы её и не нашли --- ну, и хорошо.
* Ситуация 4: закономерность была, и мы её обнаружили --- это ли не чудесно?

Ситуации 2 и 3 портят нам всю исследовательскую жизнь --- здесь возникают ошибки:

* Ситуация 2: в генеральной совокупности *закономерности нет*, однако в силу случайных причин мы её *обнаружили* на нашей выборке --- это **ошибка I рода (type I error)**.
* Ситуация 3: в генеральной совокупности *закономерность есть*, однако в силу каких-то причин мы её *не обнаружили* на нашей выборке --- это **ошибка II рода (type II error)**.

Ошибки приводят нас к некорректным выводам по результатам исследований --- соответственно, необходимо найти способ их контролировать. Для этого нам хорошо было бы каким-то образом описать сложившееся положение дел. Сделаем мы это с помощью [условной вероятности](prob-cond-prob.qmd) --- получится весьма удобная картина (@tbl-stattest-probs):

:::{#tbl-stattest-probs}

|  | $H_0$ | $H_1$ |
|:---:|:---:|:---:|
| $\hat H_0$ | $\prob (\hat H_0 | H_0)$ | $\prob (\hat H_0 | H_1) = \beta$ |
| $\hat H_1$ | $\prob (\hat H_1 | H_0) = \alpha$ | $\prob (\hat H_1 | H_1) = 1 - \beta$ |

Вероятности ошибок в ситуации тестирования статистических гипотез
:::

Почему удобно использовать именно условные вероятности? Потому что мы, разумеется, не знаем, с какой вероятностью мы находимся в ситуации $H_0$ или $H_1$, то есть мы не знаем, есть или нет в генеральной совокупности изучаемая закономерность. Однако при использовании условной вероятности мы можем рассматривать две эти ситуации отдельно: что мы можем сказать относительно результатов тестирования, (1) если закономерность в генеральной совокупности есть и (2) если закономерности в генеральной совокупности нет.

Кроме того, пользуясь свойствами условной вероятности мы получили $\prob (\hat H_1 | H_1) = 1 - \beta$, так как $\prob (\hat H_0 | H_1) + \prob (\hat H_1 | H_1) = 1$[^complete_set].

[^complete_set]: Это верно, так как события, описываемые ситуациями 2 и 4 (@tbl-stattest-situations), составляют полную группу событий.

:::{.quote .small}
--- А на кой чёрт нам эта вероятность нужна? У нас вон $\beta$ и так есть.<br>
--- Секундочку, доберемся обязательно к этом вопросу через несколько абзацев.
:::

Итак, введя интересующие нас вероятности, мы можем более пристально посмотреть на ошибки.


### Ошибка I рода и уровень значимости {#prob-hyptesting-typeIerror}

:::{.lab-junior}
:::

Ошибка I рода в каком-то смысле приятнее, так как её проще контролировать. Ещё раз вспомним, что представляет собой ошибка I рода: ситуацию, когда в генеральной совокупности **закономерности нет, но мы её нашли**. А если мы её нашли, значит у нас есть на руках какой-то *результат*, который нам говорит, что закономерность есть. Когда есть *результат*, всё становится гораздо проще --- у нас появляется возможность оценить, насколько мы потенциально ошиблись, получив этот результат. Собственно, мы можем рассчитать вероятность, с которой мы потенциально ошиблись.

Теперь у нас есть способ контроля ошибки I рода --- давайте *выберем некоторый порог вероятности ошибки*. Мы с вами, разумеется, понимаем, что полностью избежать ошибки у нас не получится --- опять же вспоминаем, что работаем со статистическими данными, которые неопределенны и вариативны. Однако выбрав в качестве порога достаточно малое значение, мы можем быть вполне уверенны, что не ошиблись.

На деле именно так и поступают --- выбирается **уровень значимости** $\alpha$, который и определяет вероятность ошибки I рода ($\prob (\hat H_1 | H_0)$) --- вероятность отклонить нулевую гипотезу при условии, что она верна.

Сразу отметим, что *уровень значимости --- это число*, некоторая константа, которую мы выбираем до начала проведения статистических тестов.

:::{.quote .small}
--- Ещё одно великое утверждение… И так ясно, что это число, что это ещё может быть…<br>
--- Отлично, что ясно. Однако мы ещё вернемся к этом замечанию, чтобы избежать распространенной путаницы.
:::

Если вы уже соприкасались с научными (да и не только) исследованиями, то наверняка вам знакомо магическое значение $0.05$. И да, действительно, в социальных науках конвенционально принятым уровнем значимости является $\alpha = 0.05$, то есть мы допускаем, что в 5% случаев мы можем ошибиться.

:::{.quote .small}
--- Чёт как-то пока не слишком понятно. Абстрактными словами бросаешься, а как оно на деле работает --- неясно. <br>
--- Понимаю, это вполне возможно. К сожалению, нам надо потратить время, чтобы ввести необходимы нам концепты и как-то их описать. Давайте сначала дойдем до статистического вывода, выстроим все нужные конструкции, а затем подробно поглядим на примеры и порисуем картинки.
:::


:::{.callout-note}
###### 0.05 не выбито на священных скрижалях

Стоит понимать, что мы в рамках нашего конкретного исследования можем выбрать и другой уровень значимости --- например, $0.01$ или даже $0.001$ --- чтобы снизить вероятность ошибки I рода. Так часто делают в медицинских исследованиях (где цена ошибки в пределе --- человеческая жизнь) или физике (где тратятся большие деньги на построение высокотехнологических сооружений типа коллайдеров, и мы должны быть очень уверенны в результатах).
:::

:::{.callout-note}
###### 5% это оч много

Если мысль из заголовка заметки вам близка, то вы не одиноки. Дебаты относительно того, что уровень значимости $0.05$ для социальных наук велик и нам необходимо что-то с этим делать, ведутся уже давно [см. напр. @benjamin2018; @lakens2018; @ruiter2019]. Мы обсудим в [отдельной главе](prob-falsepositive.qmd), как нам жить и что с этим делать, потому что сей вопрос требует весьма глубокого рассмотрения, а пока что нам надо достроить фундамент.
:::



### Ошибка II рода и статистическая мощность {#prob-hyptesting-typeIIerror}

:::{.lab-junior}
:::


### Связь ошибок I и II рода {#prob-errorconnetion}

:::{.lab-middle}
:::

Возможно, у вас возникла мысль, подобная этой:

> если мы так стремимся избежать ошибок, давайте выберем $\alpha = 0$ и $\text{power} = 1$ (т.е. $\beta = 0$), и все будет хорошо --- не будем вообще совершать ошибки!

Хм, звучит в целом справедливо. А может этому что-либо помешать?

Давайте попробуем посчитать, чему равна вероятность *отклонить* нулевую гипотезу в рамках статистического теста --- то есть вычислим $\prob (\hat H_1)$. Как нам это сделать? У нас есть условная вероятность $\prob (\hat H_1 | H_0)$, через которую мы можем выразить интересующую нас вероятность:

$$
\prob (\hat H_1) = \prob (\hat H_1 | H_0) \cdot \prob (H_0)
$$

Но ведь $\prob (\hat H_1 | H_0) = \alpha$. Следовательно,

$$
\prob (\hat H_1) = \alpha \cdot \prob (H_0)
$${#eq-alpha-prob-h1}

Да, мы не можем знать, чему на деле равна $\prob (H_0)$, но нам это и не важно --- из формулы [-@eq-alpha-prob-h1] следует, что чем меньше $\alpha$, тем меньше вероятность отклонения нулевой гипотезы:

$$
\alpha \to 0 \Rightarrow \prob (\hat H_1) \to 0
$$

:::{.callout-important .save-font-size appearance="minimal" #imp-siglevel}
Иначе говоря, если мы выберем в качестве уровня значимости $0$, то мы **никогда не сможем отклонить нулевую гипотезу**, а значит **никогда не сможем обнаружить какие-либо различия**.
:::

:::{.quote .small}
--- Так, ну хорошо. А с ошибкой II рода что?
--- Да всё так же плохо…
:::

Давайте теперь попробуем посчитать вероятность *не отклонить* нулевую гипотезу в рамках статистического теста --- то есть вычислим $\prob (\hat H_0)$. Как нам это сделать? У нас есть условная вероятность $\prob (\hat H_0 | H_1)$, через которую мы можем выразить интересующую нас вероятность:

$$
\prob (\hat H_0) = \prob (\hat H_0 | H_1) \cdot \prob (H_1)
$$

Но ведь $\prob (\hat H_0 | H_1) = \beta$. Следовательно,

$$
\prob (\hat H_0) = \beta \cdot \prob (H_1)
$${#eq-beta-prob-h0}

Да, мы вновь не можем знать, чему на деле равна $\prob (H_1)$, но нам это и здесь не важно --- из формулы [-@eq-beta-prob-h0] следует, что чем меньше $\beta$, тем меньше вероятность не отклонить нулевую гипотезу:

$$
\beta \to 0 \Rightarrow \prob (\hat H_0) \to 0
$$

А ведь вероятность ошибки II рода определяет статистическую мощность $1 - \beta$, и справедливо, что $\beta \to 0 \Rightarrow (1-\beta) \to 1$. Соответственно, и статистическая мощность, равная единице, повлечет за собой вероятность неотклонения нулевой гипотезы, равную нулю.

:::{.callout-important .save-font-size appearance="minimal" #imp-statpower}
Иначе говоря, если мы выберем в качестве статистической мощности $1$, то мы **всегда будем должны отклонять нулевую гипотезу**, а значит **никогда всегда будем обнаруживать какие-либо различия**.
:::

:::{.quote .small}
--- Прискорбная ситуация…<br>
--- В точности так…
:::

:::{.callout-important appearance="simple"}
Ввиду такого положения дел **для уровня значимости выбираются значения, близкие к нулю** (но не равные ему), а **для статистической мощности --- значения, близкие к единице** (но также не равные ей).
:::

Если внимательно присмотреться к мыслям [-@imp-siglevel] и [-@imp-statpower], то можно обнаружить следующее:

* если принять уровень значимости равным $0$, то мы с неизбежностью совершим ошибку II рода
* если принять статистическую мощность равной $1$, то мы с неизбежностью совершим ошибку I рода

Действительно, давайте посмотрим на следующие выкладки. Мы выяснили, что вероятность не отклонить нулевую гипотезу $\prob (\hat H_0)$ определяется через $\beta$ (@eq-beta-prob-h0). Но, с другой стороны,

$$
\prob (\hat H_0) = \prob (\hat H_0 | H_0) \cdot \prob (H_0)
$$

Следовательно,

$$
\beta \cdot \prob (H_1) = \prob (\hat H_0) = \prob (\hat H_0 | H_0) \cdot \prob (H_0) \Rightarrow \beta = \frac{1}{\prob (H_1)} \cdot \prob (H_0) \cdot \prob (\hat H_0 | H_0)
$$

Из таблицы [-@tbl-stattest-probs] несложно увидеть, что[^one-minus-alpha] $\prob (\hat H_0|H_0) = 1 - \alpha$. Тогда,

[^one-minus-alpha]: Так как $\prob (\hat H_0 | H_0) + \prob (\hat H_1 | H_0) = \prob (\hat H_0 | H_0) + \alpha = 1$.

$$
\beta = \frac{\prob (H_0)}{\prob (H_1)} \cdot (1 - \alpha)
$${#eq-beta-to-alpha}

$$
\alpha = 1 - \beta \cdot \frac{\prob (H_1)}{\prob (H_0)}
$${#eq-alpha-to-beta}

Что мы можем в итоге пронаблюдать?

:::{.callout-important .save-font-size appearance="minimal" #imp-alpha-beta-1}
Из формул [-@eq-beta-to-alpha] и [-@eq-alpha-to-beta] наглядно видно, что вероятности ошибок I и II рода связаны друг с другом --- ибо одна выражается через другую и наоборот.
:::

:::{.callout-important .save-font-size appearance="minimal" #imp-alpha-beta-2}
Из [-@eq-alpha-to-beta] видно, что если устремить статистическую мощность к единице --- следовательно, вероятность ошибки II рода к нулю --- то вероятность ошибки I рода будет стремиться к единице.
:::

:::{.callout-important .save-font-size appearance="minimal" #imp-alpha-beta-3}
Из [-@eq-beta-to-alpha] видно, что если устремить уровень значимости к нулю, вероятность ошибки II рода будет стремиться к единице[^beta-to-alpha-comment].
:::

[^beta-to-alpha-comment]: Внимательный читатель, конечно, возразит, что в этом случае $\beta$ будет стремится не к единице, а к отношению $\dfrac{\prob (H_1)}{\prob (H_0)}$. Это справедливо, однако для небольшого размера эффекта это отношение близко к единице. О роли размера эффекта см. далее.


:::{.callout-tip}
###### Размер эффекта решает

Для порядка отметим, что закономерности, обозначенные в [-@imp-alpha-beta-1], [-@imp-alpha-beta-2], [-@imp-alpha-beta-3] справедливы для ситуации небольшого размера эффекта, то есть когда параметры генеральных совокупностей не слишком сильно отличаются.

Если же мы имеем дело в большим размером эффекта, то жизнь становится значительно проще, вероятности ошибок практически перестают зависеть друг от друга. Далее мы визуализируем, как это работает.

Надо ли было тогда страдать над формулами? Да, эти соотношения имеет смысл себе представлять, так как на практике мы чаще всего имеем дело со средними и малыми эффектами --- особенно в нашей в сами исследовательской области.
:::

## Алгоритм тестирования статистических гипотез

:::{.lab-junior}
:::



### Асимметрия статистического вывода

:::{.lab-junior}
:::

```{=html}
<script type="text/javascript" src="./js/chapter.js"></script>
```
