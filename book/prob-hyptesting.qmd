# Тестирование статистических гипотез {#prob-hyptesting}

{{< include other/_symbols.qmd >}}

```{r opts, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, error=FALSE}
knitr::opts_chunk$set(echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, error=FALSE)
```

```{r pkgs, echo=FALSE}
library(tidyverse)
theme_set(theme_bw())
theme_update(legend.position = "bottom")
library(latex2exp)
```

::::{.intro}


:::{.callout-important}
###### Данная глава --- только основы основ!

Сразу же необходимо заявить, что в этой главе мы познакомимся только с базой тестирования статистических гипотез. Не менее важная часть изложена в [следующей главе](prob-falsepositive.qmd), которая является неотъемлемым продолжением данной. Там мы дополним картину взаимоотношений между сущностями, с которыми будем знакомиться здесь.
:::

::::



## Взаимосвязи и различия {#prob-hyptesting-hypotheses-differences}

:::{.lab-junior}
:::



## Гипотезы и данные {#prob-hyptesting-hypotheses-data}

:::{.lab-junior}
:::



## Виды гипотез {#prob-hyptesting-hypotheses}

:::{.lab-junior}
:::

**Гипотеза** ($H$, от англ. или лат. _**h**ypothesis_) --- это некоторое предположение, которое подлежит проверке на основе результатов наблюдений.

Всего можно выделить три вида гипотез --- *теоретические*, *эмпирические* и *статистические*.

* **Теоретическая гипотеза** формулируется в терминах изучаемых конструктов. 
* **Эмпирическая гипотеза** формулируется в терминах переменных, включенных в дизайн исследования.
* **Статистическая гипотеза** формулируется в терминах параметров генеральной совокупности. про данные (что мы получили в данный конкретный момент, собрав вот эти конкретные данные).

Статистические гипотезы в свою очередь делятся на два вида --- *простые* и *сложные*.

* **Простая гипотеза** представляет собой предположение, которое включает в себя однозначно сформулированное утверждение. Например, величина параметра генеральной совокупности соответствует некоторому строго заданному значению: $H : \theta = \theta_0$, где $\theta$ --- величина параметра, а $\theta_0$ --- заранее заданное значение. Другой вариант --- две генеральные совокупности обладают одним и тем же значением параметра: $H : \theta_1 = \theta_2$.
* **Сложная гипотеза** предполагает множественность вариантов значения параметра, которые укладываются в рамки проверяемого предположения. Например, $H : \theta > \theta_0$ или $H : \theta_1 \neq \theta_2$.

В ходе самого процесса тестирования гипотез выделяют *нулевую* и *альтернативную* гипотезы.

* **Нулевая гипотеза** ($H_0$) --- это гипотеза, которую мы и будем проверять в ходе тестирования. Чтобы упростить процесс тестирования гипотезы, стараются максимально упростить и саму гипотезу --- практически всегда нулевая гипотеза формулируется как *простая гипотеза*.
* **Альтернативная гипотеза** ($H_1$) --- это гипотеза, выдвигаемая в противовес нулевой. Так как нулевая гипотеза чаще всего является простой гипотезой, а значит предполагает конкретное значение параметра, то альтернативная неизбежно получается *сложной гипотезой*.


### Нулевая гипотеза {#prob-hyptesting-null-hypothesis}

:::{.lab-junior}
:::

Вариантов сформулировать нулевую гипотезу так, чтобы она была простой, всего два:

1. $H_0 : \theta = \theta_0$,
1. $H_0 : \theta_1 = \theta_2$.

Как нетрудно заметить, оба варианта *предполагают отсутствие различий*:

1. в первом случае параметр *не отличается* от некоторого заданного значения,
2. во втором параметры двух генеральных совокупностей *не отличаются* друг от друга.

:::{.callout-note .save-font-size appearance="minimal"}
Таким образом, **нулевая гипотеза --- это гипотеза об отсутствии различий**, а следовательно, об отсутствии закономерности.
:::

### Альтернативная гипотеза {#prob-hyptesting-alt-hypothesis}

:::{.lab-junior}
:::

С альтернативной гипотезой дела обстоят интереснее. Факт того, что альтернативная гипотеза является сложной, позволяет выдвинуть *три* варианта альтернативной гипотезы к нулевой гипотезе (@tbl-alt-hyp).

* Нас может интересовать полностью противоположная нулевой гипотезе ситуация. Тогда
  * для нулевой гипотезы $H_0 : \theta = \theta_0$ альтернативная гипотеза будет формулироваться как $H_1 : \theta \neq \theta_0$,
  * для нулевой гипотезы $H_0 : \theta_1 = \theta_2$ --- соответственно как $H_1 : \theta_1 \neq \theta_2$.

Ситуация $\theta \neq \theta_0$, конечно же, включается в себя и ситуацию $\theta < \theta_0$, и ситуацию $\theta > \theta_0$, то есть в качестве альтернативы мы рассматриваем *две стороны* возможных различий. Аналогично $\theta_1 \neq \theta_2 \Leftrightarrow \theta_1 < \theta_2 \wedge \theta_1 > \theta_2$[^logic_two_side].

:::{.callout-note .save-font-size appearance="minimal"}
Такие альтернативные гипотезы называются **двусторонними (two-sided hypothesis, two-tailed test)**.
:::

Они описывают ситуацию, когда различия есть, но нам не важно, куда они направлены --- (1) больше или меньше параметр $\theta$ заданного значения $\theta_0$ или (2) какой из параметров $\theta_1$ и $\theta_2$ больше другого.

[^logic_two_side]: Здесь использованы логические операторы: эквивалентность (равносильность, $\Leftrightarrow$) и конъюнкция (логическое И, $\wedge$). Подробнее см. главу «[Логика и алгебра логики](math-logic.qmd)».

* Однако нам могут быть интересны *направленные* альтернативные гипотезы.
  * Пусть для нас в рамках исследования закономерностью является то, что значение параметра будет *больше* некоторого заранее заданного значения. Тогда для нулевой гипотезы $H_0 : \theta \leq \theta_0$ альтернативная гипотеза будет формулирована как $H_1 : \theta > \theta_0$,
  * Или же с теоретических позиций мы решаем, что закономерность присутствует в случае, когда параметр первой генеральной совокупности *меньше* параметра второй генеральной совокупности. Тогда для нулевой гипотезы $H_0 : \theta_1 \geq \theta_2$ альтернативная будет выглядеть так: $H_1 : \theta_1 < \theta_2$.

Заметим, что в случае направленных альтернативных гипотез соответствующие им нулевые перестают быть простыми --- и нулевая, и альтернативная в этом случае будут сложными.

Мы можем «направить» альтернативные гипотезы и в обратную сторону, если это согласуется с теоретическими основаниями --- $H_1 : \theta < \theta_0$ и $H_1 : \theta_1 > \theta_2$ соответственно.

:::{.callout-note .save-font-size appearance="minimal"}
Такие альтернативные гипотезы называются **односторонними (one-sided hypothesis, one-tailed test)**.
:::

:::{.callout-note .save-font-size appearance="minimal"}
Если нас интересует ситуация «меньше», то гипотеза называется **левосторонней (left-tailed test)**.
:::

:::{.callout-note .save-font-size appearance="minimal"}
Если же нас интересует ситуация «больше», то гипотеза будет **правосторонней (right-tailed test)**.
:::

::: {#tbl-alt-hyp}

| | Гипотеза о равенстве параметра заданному значению | Гипотеза о равенстве значений двух параметров |
|---|---|---|
| Двусторонняя альтернатива | $H_0 : \theta = \theta_0$ <br> $H_1 : \theta \neq \theta_0$ 	| $H_0 : \theta_1 = \theta_2$ <br> $H_1 : \theta_1 \neq \theta_2$ 	|
| Односторонняя альтернатива (левосторонняя)  	| $H_0 : \theta \geq \theta_0$ <br> $H_1 : \theta < \theta_0$    	| $H_0 : \theta_1 \geq \theta_2$ <br> $H_1 : \theta_1 < \theta_2$    	|
| Односторонняя альтернатива (правосторонняя) 	| $H_0 : \theta \leq \theta_0$ <br> $H_1 : \theta > \theta_0$    	| $H_0 : \theta_1 \leq \theta_2$ <br> $H_1 : \theta_1 > \theta_2$    	|

Нулевые и альтернативные гипотезы: односторонние и двусторонние альтернативы.
:::

На что будет влиять «сторонность» гипотезы? И как выбрать, какая нам нужна в конкретном исследовании? Мы обязательно ответим на эти вопросы, но чуть позже --- пока что нам не хватает знаний, чтобы пронаблюдать возможные последствия.



## Возможные результаты проверки гипотез {#prob-hyptesting-results}

:::{.lab-junior}
:::

Изучая в исследовании какую-либо закономерность, мы достоверно не знаем, существует ли она в реальном мире. «*В реальном мире*» в данном контексте означает «*на уровне генеральных совокупностей*». Почему мы не знаем --- и не можем знать --- об этом достоверно? Причина такого положения дел нам хорошо известна: генеральная совокупность недоступна для наблюдения в полном объеме. Тем не менее, в мире ~~идей~~ генеральных совокупностей закономерность **может существовать**, а **может и не существовать**.

:::{.quote .small .pers}
--- Ну, тоже мне, великое умозаключение! Это же предельно очевидно!<br>
--- Да, но давайте посмотрим, что получается дальше.
:::

Имея дело с выборкой, мы вспоминаем о двух ключевых характеристиках статистических данных --- их **неопределенности** и **вариативности**[^statdata]. В силу этих характеристик мы можем на отдельной выборке **либо обнаружить** интересующую нас закономерность, **либо не обнаружить**.

[^statdata]: Если вы успели подзабыть, что это такое, посмотрите [этот раздел](desc-statintro.qmd#desc-statintro-statdata).

:::{.quote .small .pers}
--- Ну, ясно же! Если закономерность есть, то мы её обнаружим, если нет --- то не обнаружим!<br>
--- Ах, если бы это было так…
:::

Поскольку ни одно исследование не является идеальным, мы можем обнаружить или не обнаружить исследуемую закономерность как в ситуации наличия её в генеральной совокупности, так и в ситуации отсутствия таковой.

В качестве нулевой гипотезы мы выдвигаем предположение о том, что изучаемая закономерность отсутствует --- так мы упрощаем нашу нулевую гипотезу. Пусть $H_0$ обозначает, что предположение об отсутствии закономерности справедливо, а $H_1$ --- что это предположение не справедливо. Иначе говоря, $H_0$ обозначает ситуацию, что **закономерности в генеральной совокупности нет**, а $H_1$ --- что **закономерность в генеральной совокупности есть**.

На основании данных, собранных на отдельной выборке, мы можем либо не отклонить наше предположение (нулевую гипотезу), то есть **не обнаружить закономерность**, либо отклонить исходное предположение (нулевую гипотезу), то есть **обнаружить закономерность**. Обозначим ситуацию, когда мы *не обнаружили* закономерность как $\hat H_0$, а ситуацию, когда мы *обнаружили закономерность*, как $\hat H_1$. Поскольку сейчас мы работаем с выборкой, то ашки у нас в шляпках.

Тогда при тестировании статистических гипотез возможны следующие ситуации (@tbl-stattest-situations):

:::{#tbl-stattest-situations}

|  | $H_0$ | $H_1$ |
|:---:|:---:|:---:|
| $\hat H_0$ | **Ситуация 1**<br> ✓ | **Ситуация 2**<br> Ошибка II рода (Type II Error) |
| $\hat H_1$ | **Ситуация 3**<br> Ошибка I рода (Type I Error) | **Ситуация 4**<br> ✓ |

Ситуации, возникающие при тестировании статистических гипотез
:::

Ситуации 1 и 4 нас полностью устраивают:

* Ситуация 1: не было закономерности, мы её и не нашли --- ну, и хорошо.
* Ситуация 4: закономерность была, и мы её обнаружили --- это ли не чудесно?

Ситуации 2 и 3 портят нам всю исследовательскую жизнь --- здесь возникают ошибки:

* Ситуация 2: в генеральной совокупности *закономерности нет*, однако в силу случайных причин мы её *обнаружили* на нашей выборке --- это **ошибка I рода (type I error)**.
* Ситуация 3: в генеральной совокупности *закономерность есть*, однако в силу каких-то причин мы её *не обнаружили* на нашей выборке --- это **ошибка II рода (type II error)**.

Ошибки приводят нас к некорректным выводам по результатам исследований --- соответственно, необходимо найти способ их контролировать. Для этого нам хорошо было бы каким-то образом описать сложившееся положение дел. Сделаем мы это с помощью [условной вероятности](prob-cond-prob.qmd) --- получится весьма удобная картина (@tbl-stattest-probs):

:::{#tbl-stattest-probs}

|  | $H_0$ | $H_1$ |
|:---:|:---:|:---:|
| $\hat H_0$ | $\prob (\hat H_0 | H_0)$ | $\prob (\hat H_0 | H_1) = \beta$ |
| $\hat H_1$ | $\prob (\hat H_1 | H_0) = \alpha$ | $\prob (\hat H_1 | H_1) = 1 - \beta$ |

Вероятности ошибок в ситуации тестирования статистических гипотез
:::

Почему удобно использовать именно условные вероятности? Потому что мы, разумеется, не знаем, с какой вероятностью мы находимся в ситуации $H_0$ или $H_1$, то есть мы не знаем, есть или нет в генеральной совокупности изучаемая закономерность. Однако при использовании условной вероятности мы можем рассматривать две эти ситуации отдельно: что мы можем сказать относительно результатов тестирования, (1) если закономерность в генеральной совокупности есть и (2) если закономерности в генеральной совокупности нет.

Кроме того, пользуясь свойствами условной вероятности мы получили $\prob (\hat H_1 | H_1) = 1 - \beta$, так как $\prob (\hat H_0 | H_1) + \prob (\hat H_1 | H_1) = 1$[^complete_set].

[^complete_set]: Это верно, так как события, описываемые ситуациями 2 и 4 (@tbl-stattest-situations), составляют полную группу событий.

:::{.quote .small .pers}
--- А на кой чёрт нам эта вероятность нужна? У нас вон $\beta$ и так есть.<br>
--- Секундочку, доберемся обязательно к этом вопросу через несколько абзацев.
:::

Итак, введя интересующие нас вероятности, мы можем более пристально посмотреть на ошибки.


### Ошибка I рода и уровень значимости {#prob-hyptesting-typeIerror}

:::{.lab-junior}
:::

Ошибка I рода в каком-то смысле приятнее, так как её проще контролировать. Ещё раз вспомним, что представляет собой ошибка I рода: ситуацию, когда в генеральной совокупности **закономерности нет, но мы её нашли**. А если мы её нашли, значит у нас есть на руках какой-то *результат*, который нам говорит, что закономерность есть. Когда есть *результат*, всё становится гораздо проще --- у нас появляется возможность оценить, насколько мы потенциально ошиблись, получив этот результат. Собственно, мы можем рассчитать вероятность, с которой мы потенциально ошиблись.

Теперь у нас есть способ контроля ошибки I рода --- давайте *выберем некоторый порог вероятности ошибки*. Мы с вами, разумеется, понимаем, что полностью избежать ошибки у нас не получится --- опять же вспоминаем, что работаем со статистическими данными, которые неопределенны и вариативны. Однако выбрав в качестве порога достаточно малое значение, мы можем быть вполне уверенны, что не ошиблись.

На деле именно так и поступают --- выбирается **уровень значимости** $\alpha$, который и определяет вероятность ошибки I рода ($\prob (\hat H_1 | H_0)$) --- вероятность отклонить нулевую гипотезу при условии, что она верна.

Сразу отметим, что *уровень значимости --- это число*, некоторая константа, которую мы выбираем до начала проведения статистических тестов.

:::{.quote .small .pers}
--- Ещё одно великое утверждение… И так ясно, что это число, что это ещё может быть…<br>
--- Отлично, что ясно. Однако мы ещё вернемся к этом замечанию, чтобы избежать распространенной путаницы.
:::

Если вы уже соприкасались с научными (да и не только) исследованиями, то наверняка вам знакомо магическое значение $0.05$. И да, действительно, в социальных науках конвенционально принятым уровнем значимости является $\alpha = 0.05$, то есть мы допускаем, что в 5% случаев мы можем ошибиться.

:::{.quote .small .pers}
--- Чёт как-то пока не слишком понятно. Абстрактными словами бросаешься, а как оно на деле работает --- неясно. <br>
--- Понимаю, это вполне возможно. К сожалению, нам надо потратить время, чтобы ввести необходимы нам концепты и как-то их описать. Давайте сначала дойдем до статистического вывода, выстроим все нужные конструкции, а затем подробно поглядим на примеры и порисуем картинки.
:::


:::{.callout-note}
###### 0.05 не выбито на священных скрижалях

Стоит понимать, что мы в рамках нашего конкретного исследования можем выбрать и другой уровень значимости --- например, $0.01$ или даже $0.001$ --- чтобы снизить вероятность ошибки I рода. Так часто делают в медицинских исследованиях (где цена ошибки в пределе --- человеческая жизнь) или физике (где тратятся большие деньги на построение высокотехнологических сооружений типа коллайдеров, и мы должны быть очень уверенны в результатах).
:::

:::{.callout-note}
###### 5% это оч много

Если мысль из заголовка заметки вам близка, то вы не одиноки. Дебаты относительно того, что уровень значимости $0.05$ для социальных наук велик и нам необходимо что-то с этим делать, ведутся уже давно [см. напр. @benjamin2018; @lakens2018; @ruiter2019]. Мы обсудим в [отдельной главе](prob-falsepositive.qmd), как нам жить и что с этим делать, потому что сей вопрос требует весьма глубокого рассмотрения, а пока что нам надо достроить фундамент.
:::



### Ошибка II рода и статистическая мощность {#prob-hyptesting-typeIIerror}

:::{.lab-junior}
:::


### Связь ошибок I и II рода {#prob-errorconnection}

:::{.lab-middle}
:::

Возможно, у вас возникла мысль, подобная этой:

> если мы так стремимся избежать ошибок, давайте выберем $\alpha = 0$ и $\text{power} = 1$ (т.е. $\beta = 0$), и все будет хорошо --- не будем вообще совершать ошибки!

Хм, звучит в целом справедливо. А может этому что-либо помешать?

Давайте попробуем посчитать, чему равна вероятность *отклонить* нулевую гипотезу в рамках статистического теста --- то есть вычислим $\prob (\hat H_1)$. Как нам это сделать? У нас есть условная вероятность $\prob (\hat H_1 | H_0)$, через которую мы можем выразить интересующую нас вероятность:

$$
\prob (\hat H_1) = \prob (\hat H_1 | H_0) \cdot \prob (H_0)
$$

Но ведь $\prob (\hat H_1 | H_0) = \alpha$. Следовательно,

$$
\prob (\hat H_1) = \alpha \cdot \prob (H_0)
$${#eq-alpha-prob-h1}

Да, мы не можем знать, чему на деле равна $\prob (H_0)$, но нам это и не важно --- из формулы [-@eq-alpha-prob-h1] следует, что чем меньше $\alpha$, тем меньше вероятность отклонения нулевой гипотезы:

$$
\alpha \to 0 \Rightarrow \prob (\hat H_1) \to 0
$$

:::{.callout-important .save-font-size appearance="minimal" #imp-siglevel}
Иначе говоря, если мы выберем в качестве уровня значимости $0$, то мы **никогда не сможем отклонить нулевую гипотезу**, а значит **никогда не сможем обнаружить какие-либо различия**.
:::

:::{.quote .small .pers}
--- Так, ну хорошо. А с ошибкой II рода что? <br>
--- Да всё так же плохо…
:::

Давайте теперь попробуем посчитать вероятность *не отклонить* нулевую гипотезу в рамках статистического теста --- то есть вычислим $\prob (\hat H_0)$. Как нам это сделать? У нас есть условная вероятность $\prob (\hat H_0 | H_1)$, через которую мы можем выразить интересующую нас вероятность:

$$
\prob (\hat H_0) = \prob (\hat H_0 | H_1) \cdot \prob (H_1)
$$

Но ведь $\prob (\hat H_0 | H_1) = \beta$. Следовательно,

$$
\prob (\hat H_0) = \beta \cdot \prob (H_1)
$${#eq-beta-prob-h0}

Да, мы вновь не можем знать, чему на деле равна $\prob (H_1)$, но нам это и здесь не важно --- из формулы [-@eq-beta-prob-h0] следует, что чем меньше $\beta$, тем меньше вероятность не отклонить нулевую гипотезу:

$$
\beta \to 0 \Rightarrow \prob (\hat H_0) \to 0
$$

А ведь вероятность ошибки II рода определяет статистическую мощность $1 - \beta$, и справедливо, что $\beta \to 0 \Rightarrow (1-\beta) \to 1$. Соответственно, и статистическая мощность, равная единице, повлечет за собой вероятность неотклонения нулевой гипотезы, равную нулю.

:::{.callout-important .save-font-size appearance="minimal" #imp-statpower}
Иначе говоря, если мы выберем в качестве статистической мощности $1$, то мы **всегда будем должны отклонять нулевую гипотезу**, а значит **никогда всегда будем обнаруживать какие-либо различия**.
:::

:::{.quote .small .pers}
--- Прискорбная ситуация…<br>
--- В точности так…
:::

:::{.callout-important appearance="simple"}
Ввиду такого положения дел **для уровня значимости выбираются значения, близкие к нулю** (но не равные ему), а **для статистической мощности --- значения, близкие к единице** (но также не равные ей).
:::

Если внимательно присмотреться к мыслям [-@imp-siglevel] и [-@imp-statpower], то можно обнаружить следующее:

* если принять уровень значимости равным $0$, то мы с неизбежностью совершим ошибку II рода
* если принять статистическую мощность равной $1$, то мы с неизбежностью совершим ошибку I рода

Действительно, давайте посмотрим на следующие выкладки. Мы выяснили, что вероятность не отклонить нулевую гипотезу $\prob (\hat H_0)$ определяется через $\beta$ (@eq-beta-prob-h0). Но, с другой стороны,

$$
\prob (\hat H_0) = \prob (\hat H_0 | H_0) \cdot \prob (H_0)
$$

Следовательно,

$$
\beta \cdot \prob (H_1) = \prob (\hat H_0) = \prob (\hat H_0 | H_0) \cdot \prob (H_0) \Rightarrow \beta = \frac{1}{\prob (H_1)} \cdot \prob (H_0) \cdot \prob (\hat H_0 | H_0)
$$

Из таблицы [-@tbl-stattest-probs] несложно увидеть, что[^one-minus-alpha] $\prob (\hat H_0|H_0) = 1 - \alpha$. Тогда,

[^one-minus-alpha]: Так как $\prob (\hat H_0 | H_0) + \prob (\hat H_1 | H_0) = \prob (\hat H_0 | H_0) + \alpha = 1$.

$$
\beta = \frac{\prob (H_0)}{\prob (H_1)} \cdot (1 - \alpha)
$${#eq-beta-to-alpha}

$$
\alpha = 1 - \beta \cdot \frac{\prob (H_1)}{\prob (H_0)}
$${#eq-alpha-to-beta}

Что мы можем в итоге пронаблюдать?

:::{.callout-important .save-font-size appearance="minimal" #imp-alpha-beta-1}
Из формул [-@eq-beta-to-alpha] и [-@eq-alpha-to-beta] наглядно видно, что вероятности ошибок I и II рода связаны друг с другом --- ибо одна выражается через другую и наоборот.
:::

:::{.callout-important .save-font-size appearance="minimal" #imp-alpha-beta-2}
Из [-@eq-alpha-to-beta] видно, что если устремить статистическую мощность к единице --- следовательно, вероятность ошибки II рода к нулю --- то вероятность ошибки I рода будет стремиться к единице.
:::

:::{.callout-important .save-font-size appearance="minimal" #imp-alpha-beta-3}
Из [-@eq-beta-to-alpha] видно, что если устремить уровень значимости к нулю, вероятность ошибки II рода будет стремиться к единице[^beta-to-alpha-comment].
:::

[^beta-to-alpha-comment]: Внимательный читатель, конечно, возразит, что в этом случае $\beta$ будет стремится не к единице, а к отношению $\dfrac{\prob (H_1)}{\prob (H_0)}$. Это справедливо, однако для небольшого размера эффекта это отношение близко к единице. О роли размера эффекта см. далее.


:::{.callout-tip}
###### Размер эффекта решает

Для порядка отметим, что закономерности, обозначенные в [-@imp-alpha-beta-1], [-@imp-alpha-beta-2], [-@imp-alpha-beta-3] справедливы для ситуации небольшого размера эффекта, то есть когда параметры генеральных совокупностей не слишком сильно отличаются.

Если же мы имеем дело в большим размером эффекта, то жизнь становится значительно проще, так как вероятности ошибок практически перестают зависеть друг от друга. Далее мы визуализируем, как это работает.

Надо ли было тогда страдать над формулами? Да, эти соотношения имеет смысл себе представлять, так как на практике мы чаще всего имеем дело со средними и малыми эффектами --- особенно в нашей с вами исследовательской области.
:::

## Алгоритм тестирования статистических гипотез {#prob-hyptesting-algorithm}

:::{.lab-junior}
:::


### Путь первый {#prob-hyptesting-algorithm-opt1}

:::{.lab-junior}
:::

:::{.callout-note}
###### Алгоритм тестирования статистических гипотез [Вариант 1]

1. Формулировка гипотез
1. Выбор статистического критерия
1. Выбор уровня значимости $α$
1. Построение закона распределения статистики критерия при условии, что нулевая гипотеза верна
1. Определение границ критической области
    * Для *односторонней* альтернативы одно критическое значение $t_{\cr}$
    * Для *двусторонней* альтернативы два критических значения $t_{\cr1}$ и $t_{\cr2}$, такие что $t_{\cr1} < t_{\cr2}$[^stat-inf-sym-dist-1]
1. Расчёт выборочной статистики $t_o$
1. Определение, попадает ли наблюдаемое значение статистики в критическую область
1. Статистический вывод
:::

:::{.callout-note}
###### Статистический вывод [Вариант 1]

* Если значение выборочной статистики *попадает* в границы критической области, то мы *имеем основания отклонить нулевую гипотезу* $H_0$ и принять альтернативную $H_1$.
    * Для *левосторонней* альтернативы $t_o < t_{\cr}$
    * Для *правосторонней* альтернативы $t_o > t_{\cr}$
    * Для *двусторонней* альтернативы $t_o < t_{\cr1} \or t_o > t_{\cr2}$[^stat-inf-sym-dist-2]
* Если значение выборочной статистики **не** *попадает* в границы критической области, то мы **не** *имеем оснований отклонить нулевую гипотезу* $H_0$ и принять альтернативную $H_1$.
    * Для *левосторонней* альтернативы $t_o > t_{\cr}$
    * Для *правосторонней* альтернативы $t_o < t_{\cr}$
    * Для *двусторонней* альтернативы $t_o > t_{\cr1} \and t_o < t_{\cr2}$[^stat-inf-sym-dist-3]

:::

[^stat-inf-sym-dist-1]: В случае, если распределение статистики критерия симметрично --- что встречается довольно часто --- можно рассматривать модуль критического значения $|t_{\cr}|$, так как оба критических значения будут равны по модулю, но противоположны по знаку: $t_{\cr1} = -t_{\cr2}$.

[^stat-inf-sym-dist-2]: В случае, если распределение статистики критерия симметрично, можно упростить данное условие до $|t_o| > |t_{\cr}|$.

[^stat-inf-sym-dist-3]: В случае, если распределение статистики критерия симметрично, можно упростить данное условие до $|t_o| < |t_{\cr}|$.


:::{#exm-hyptesting-opt1-h0-greater}
Студенты одной из академических групп первого курса факультета психологии некоторого вуза прошли тестирование на интеллект с помощью теста IQ. В тестировании принято участие 35 человек. Средний балл студентов оказался равен 102.77. Проверьте гипотезу о том, что уровень интеллекта в этой группе выше среднего.
:::

**Шаг 1. Формулировка гипотез.** В данном случае можно сформулировать следующие гипотезы:

* *Теоретическая гипотеза*: интеллект студентов выше по сравнению со средним для их возраста
* *Эмпирическая гипотеза*: средний балл IQ студентов больше среднего значения по данной шкале
* *Статистические гипотезы*:
    * $H_0 : \mu \leq 100$
    * $H_1 : \mu > 100$

**Шаг 2. Выбор статистического критерия.** Для тестирования такой статистической гипотезы в данном случае подойдёт z-тест (z-критерий Фишера), позволяющий сравнить выборочное среднее с заданным значением, так как дисперсия распределения известна. Он вычисляется по следующей формуле:

$$
z = \frac{\overline X - \mu_0}{\se},
$$

где $\overline X$ --- выборочное среднее, $\mu_0$ --- заданное значение параметра, $\se$ --- стандартная ошибка, вычисляемая как $\displaystyle \se = \frac{\sigma}{\sqrt{n}}$, $\sigma$ --- стандартное отклонение.

**Шаг 3. Выбор уровня значимости.** Возьмем дефолтное значение $\alpha = 0.05$.

**Шаг 4. Построение закона распределения статистики критерия при условии, что нулевая гипотеза верна.** z-статистика подчиняется стандартному нормальному распределению $z \disted{H_0} \norm(0, 1)$.

```{r}
ggplot(NULL) +
  stat_function(fun = dnorm) +
  xlim(-4, 4) +
  labs(x = "z", y = "Density")
```

**Шаг 5. Определение границ критической области.** 

$$
z_{\cr} = 1.645
$$

:::{.callout-note appearance="simple" collapse="true"}
###### Таблица критических значений z-статистики для односторонней альтернативной гипотезы

```{r z-crit-one-tailed-table}
tibble(alpha = c(0.05, 0.01, 0.001),
       z = qnorm(alpha) %>% round(3)) %>% 
  mutate(z = str_replace(z, "-", "±")) %>% 
  knitr::kable(digits = 3, col.names = c("$\\alpha$", "$z_{\\cr}$"))
```
:::

```{r}
ggplot(NULL) +
  stat_function(fun = dnorm,
                geom = "area",
                xlim = c(qnorm(1 - 0.05), 4),
                alpha = .5, fill = "red") +
  stat_function(fun = dnorm) +
  geom_vline(xintercept = qnorm(1 - 0.05), linetype = "dotted") +
  annotate(geom = "text", label = TeX("$z_{cr}$"),
           x = 1.8, y = 0.4) +
  annotate(geom = "text", label = TeX("$\\alpha$"),
           x = 2, y = 0.02, color = "darkred") +
  scale_x_continuous(breaks = c(-4, -3, -2, -1, 0, 1, qnorm(1 - 0.05), 2, 3, 4) %>% round(2),
                     limits = c(-4, 4), 
                     minor_breaks = NULL) +
  labs(x = "z", y = "Density")
```

**Шаг 6. Расчёт выборочной статистики $z_o$.**

$$
z_o = \frac{\overline X - \mu_0}{\sigma / \sqrt{n}} = \frac{102.77 - 100}{15 / \sqrt{35}} \approx 1.09
$$

**Шаг 7. Определение, попадает ли наблюдаемое значение статистики в критическую область.**

```{r}
n <- 35
mu <- 102.77
mu0 <- 100
s <- 15
z_o <- (mu - mu0) / (s / sqrt(n))
ggplot(NULL) +
  stat_function(fun = dnorm,
                geom = "area",
                xlim = c(qnorm(1 - 0.05), 4),
                alpha = .5, fill = "red") +
  stat_function(fun = dnorm) +
  geom_vline(xintercept = qnorm(1 - 0.05), linetype = "dotted") +
  geom_vline(xintercept = z_o, linetype = "dashed") +
  annotate(geom = "text", label = TeX("$z_{cr}$"),
           x = 1.8, y = 0.4) +
  annotate(geom = "text", label = TeX("$z_{o}$"),
           x = 1.25, y = 0.4) +
  annotate(geom = "text", label = TeX("$\\alpha$"),
           x = 2, y = 0.02, color = "darkred") +
  scale_x_continuous(breaks = c(-4, -3, -2, -1, 0, 1, qnorm(1 - 0.05), 2, 3, 4) %>% round(2),
                     limits = c(-4, 4), 
                     minor_breaks = NULL) +
  labs(x = "z", y = "Density")
```

**Шаг 8. Статистический вывод.**

Так как $z_o < z_{\cr}$, то по результатам статистического тестирования мы получили значение $z$-статистики, *характерное* для случая, когда *нулевая гипотеза верна*, следовательно у нас нет оснований отклонять нулевую гипотезу о равенстве выборочного среднего значению 100.



:::{#exm-hyptesting-opt1-h1-greater}
Студенты другой академической группы первого курса факультета психологии того же вуза также прошли тестирование на интеллект с помощью теста IQ. В тестировании принято участие 32 человека. Средний балл студентов оказался равен 106.19. Проверьте гипотезу о том, что уровень интеллекта в этой группе выше среднего.
:::

**Шаг 1. Формулировка гипотез.** Так как суть задачи не изменилась --- иными стали только данные --- то гипотезы останутся теми же:

* *Теоретическая гипотеза*: интеллект студентов выше по сравнению со средним для их возраста
* *Эмпирическая гипотеза*: средний балл IQ студентов больше среднего значения по данной шкале
* *Статистические гипотезы*:
    * $H_0 : \mu \leq 100$
    * $H_1 : \mu > 100$

**Шаг 2. Выбор статистического критерия.** Поскольку гипотезы остались прежними, мы вновь сможем воспользоваться z-тестом (z-критерий Фишера):

$$
z = \frac{\overline X - \mu_0}{\se},
$$

где $\overline X$ --- выборочное среднее, $\mu_0$ --- заданное значение параметра, $\se$ --- стандартная ошибка, вычисляемая как $\displaystyle \se = \frac{\sigma}{\sqrt{n}}$, $\sigma$ --- стандартное отклонение.

**Шаг 3. Выбор уровня значимости.** Также оставим дефолтное значение $\alpha = 0.05$.

**Шаг 4. Построение закона распределения статистики критерия при условии, что нулевая гипотеза верна.** z-статистика всё ещё подчиняется стандартному нормальному распределению $z \disted{H_0} \norm(0, 1)$.

```{r}
ggplot(NULL) +
  stat_function(fun = dnorm) +
  xlim(-4, 4) +
  labs(x = "z", y = "Density")
```

**Шаг 5. Определение границ критической области.** 

Не изменилось и критическое значение, так как оно определяется уровнем значимости, а он остался прежним.

$$
z_{\cr} = 1.645
$$

```{r}
ggplot(NULL) +
  stat_function(fun = dnorm,
                geom = "area",
                xlim = c(qnorm(1 - 0.05), 4),
                alpha = .5, fill = "red") +
  stat_function(fun = dnorm) +
  geom_vline(xintercept = qnorm(1 - 0.05), linetype = "dotted") +
  annotate(geom = "text", label = TeX("$z_{cr}$"),
           x = 1.8, y = 0.4) +
  annotate(geom = "text", label = TeX("$\\alpha$"),
           x = 2, y = 0.02, color = "darkred") +
  scale_x_continuous(breaks = c(-4, -3, -2, -1, 0, 1, qnorm(1 - 0.05), 2, 3, 4) %>% round(2),
                     limits = c(-4, 4), 
                     minor_breaks = NULL) +
  labs(x = "z", y = "Density")
```

**Шаг 6. Расчёт выборочной статистики $z_o$.** А вот здесь начинаются изменения. Так как у нас появились новые данные, изменится и значение z-статистики:

$$
z_o = \frac{\overline X - \mu_0}{\sigma / \sqrt{n}} = \frac{106.19 - 100}{15 / \sqrt{32}} \approx 2.33
$$

**Шаг 7. Определение, попадает ли наблюдаемое значение статистики в критическую область.**

```{r}
n <- 32
mu <- 106.19
mu0 <- 100
s <- 15
z_o <- (mu - mu0) / (s / sqrt(n))
ggplot(NULL) +
  stat_function(fun = dnorm,
                geom = "area",
                xlim = c(qnorm(1 - 0.05), 4),
                alpha = .5, fill = "red") +
  stat_function(fun = dnorm) +
  geom_vline(xintercept = qnorm(1 - 0.05), linetype = "dotted") +
  geom_vline(xintercept = z_o, linetype = "dashed") +
  annotate(geom = "text", label = TeX("$z_{cr}$"),
           x = 1.8, y = 0.4) +
  annotate(geom = "text", label = TeX("$z_{o}$"),
           x = 2.5, y = 0.4) +
  annotate(geom = "text", label = TeX("$\\alpha$"),
           x = 2, y = 0.02, color = "darkred") +
  scale_x_continuous(breaks = c(-4, -3, -2, -1, 0, 1, qnorm(1 - 0.05), 2, 3, 4) %>% round(2),
                     limits = c(-4, 4), 
                     minor_breaks = NULL) +
  labs(x = "z", y = "Density")
```

**Шаг 8. Статистический вывод.**

Так как $z_o > z_{\cr}$, то по результатам статистического тестирования мы получили значение $z$-статистики, *нехарактерное* для случая, когда *нулевая гипотеза верна*, следовательно у нас *есть основания* отклонить нулевую гипотезу и *принять альтернативную*, что выборочное среднее больше 100.





```{r}
set.seed(65)
iq4 <- rnorm(23, mean = 100, sd = 15) %>% round()
mean(iq4)
BSDA::z.test(iq4, mu = 100, sigma.x = 15, alternative = "less")
```

:::{#exr-hyptesting-opt1-h1-lower}
Вместе с коллегами студенты третьей академической группы первого курса факультета психологии уже известного нам вуза принимали участие в тестировании на интеллект с помощью теста IQ. Было протестировано 23 человека, их средний балл составил 94.17. Администрация страшно паникует, смотря на такие результаты, ибо считает, что интеллект группы ниже среднего. Есть ли повод для паники?
:::

::::{.solution}
:::{.cell}
Алгоритм остаётся таким же, поэтому тезисно:

1. *Гипотезы*:
    * *Теоретическая*: интеллект студентов ниже по сравнению со средним для их возраста
    * *Эмпирическая*: средний балл IQ студентов ниже среднего значения по данной шкале
    * *Статистические*:
        * $H_0: \mu \geq 100$
        * $H_1: \mu < 100$
2. *Статистический критерий*: $\displaystyle z = \frac{\overline X - \mu_0}{\sigma / \sqrt{n}}$
3. *Уровень значимости*: $\alpha = 0.05$
4. *Распределение при справедливости нулевой гипотезы*: $z \disted{H_0} \norm(0, 1)$
5. *Критическое значение*: $z_{\cr} = -1.645$
6. *Расчёт выборочной статистики*: $\displaystyle z_o = \frac{94.17 - 100}{15 / \sqrt{23}} \approx -1.86$
7. *Сравнение с критическим значением*: $z_o < z_{\cr}$
8. *Статистический вывод*: так как $z_o < z_{\cr}$, то по результатам статистического тестирования мы получили значение $z$-статистики, *нехарактерное* для случая, когда *нулевая гипотеза верна*, следовательно у нас *есть основания* отклонить нулевую гипотезу и *принять альтернативную*, что выборочное среднее меньше 100.

```{r}
n <- 23
mu <- 94.17
mu0 <- 100
s <- 15
z_o <- (mu - mu0) / (s / sqrt(n))
ggplot(NULL) +
  stat_function(fun = dnorm,
                geom = "area",
                xlim = c(-4, qnorm(0.05)),
                alpha = .5, fill = "red") +
  stat_function(fun = dnorm) +
  geom_vline(xintercept = qnorm(0.05), linetype = "dotted") +
  geom_vline(xintercept = z_o, linetype = "dashed") +
  annotate(geom = "text", label = TeX("$z_{cr}$"),
           x = -1.45, y = 0.4) +
  annotate(geom = "text", label = TeX("$z_{o}$"),
           x = -2.1, y = 0.4) +
  annotate(geom = "text", label = TeX("$\\alpha$"),
           x = -2, y = 0.02, color = "darkred") +
  scale_x_continuous(breaks = c(-4, -3, -2, -1, 0, 1, qnorm(0.05), 2, 3, 4) %>% round(2),
                     limits = c(-4, 4), 
                     minor_breaks = NULL) +
  labs(x = "z", y = "Density")
```

:::
::::


```{r}
set.seed(99)
iq3 <- rnorm(35, mean = 100, sd = 15) %>% round()
mean(iq3)
BSDA::z.test(iq3, mu = 100, sigma.x = 15, alternative = "less")
```

:::{#exr-hyptesting-opt1-h0-lower}
Четвёртой академической группе первого курса факультета психологии всё того же вуза тоже пришлось участвовать в тестировании на интеллект с помощью теста IQ. Участие в этом мероприятии приняло 35 человек, а средний балл студентов оказался равен 97.77. Администрация и по этому поводу паникует, так как предполагает, что у группы интеллект ниже среднего. Так ли это?
:::

::::{.solution}
:::{.cell}
Алгоритм остаётся таким же, поэтому тезисно:

1. *Гипотезы*:
    * *Теоретическая*: интеллект студентов ниже по сравнению со средним для их возраста
    * *Эмпирическая*: средний балл IQ студентов ниже среднего значения по данной шкале
    * *Статистические*:
        * $H_0: \mu \geq 100$
        * $H_1: \mu < 100$
2. *Статистический критерий*: $\displaystyle z = \frac{\overline X - \mu_0}{\sigma / \sqrt{n}}$
3. *Уровень значимости*: $\alpha = 0.05$
4. *Распределение при справедливости нулевой гипотезы*: $z \disted{H_0} \norm(0, 1)$
5. *Критическое значение*: $z_{\cr} = -1.645$
6. *Расчёт выборочной статистики*: $\displaystyle z_o = \frac{97.77 - 100}{15 / \sqrt{35}} \approx -0.88$
7. *Сравнение с критическим значением*: $z_o > z_{\cr}$
8. *Статистический вывод*: так как $z_o > z_{\cr}$, то по результатам статистического тестирования мы получили значение $z$-статистики, *характерное* для случая, когда *нулевая гипотеза верна*, следовательно у нас *нет оснований* отклонить нулевую гипотезу о равенстве выборочного среднего значению 100..

```{r}
n <- 35
mu <- 97.77
mu0 <- 100
s <- 15
z_o <- (mu - mu0) / (s / sqrt(n))
ggplot(NULL) +
  stat_function(fun = dnorm,
                geom = "area",
                xlim = c(-4, qnorm(0.05)),
                alpha = .5, fill = "red") +
  stat_function(fun = dnorm) +
  geom_vline(xintercept = qnorm(0.05), linetype = "dotted") +
  geom_vline(xintercept = z_o, linetype = "dashed") +
  annotate(geom = "text", label = TeX("$z_{cr}$"),
           x = -1.45, y = 0.4) +
  annotate(geom = "text", label = TeX("$z_{o}$"),
           x = -0.7, y = 0.4) +
  annotate(geom = "text", label = TeX("$\\alpha$"),
           x = -2, y = 0.02, color = "darkred") +
  scale_x_continuous(breaks = c(-4, -3, -2, -1, 0, 1, qnorm(0.05), 2, 3, 4) %>% round(2),
                     limits = c(-4, 4), 
                     minor_breaks = NULL) +
  labs(x = "z", y = "Density")
```

:::
::::











:::{.callout-note appearance="simple" collapse="true"}
###### Таблица критических значений z-статистики для двусторонней альтернативной гипотезы

```{r z-crit-two-tailed-table}
tibble(alpha = c(0.05, 0.01, 0.001),
       z = qnorm(alpha/2) %>% round(3)) %>% 
  mutate(z = str_replace(z, "-", "±")) %>% 
  knitr::kable(digits = 3, col.names = c("$\\alpha$", "$z_{\\cr}$"))
```
:::





### Путь второй {#prob-hyptesting-algorithm-opt2}

:::{.lab-junior}
:::

:::{.callout-note}
###### Алгоритм тестирования статистических гипотез [Вариант 2]

1. Формулировка гипотез
1. Выбор статистического критерия
1. Выбор уровня значимости $α$
1. Построение закона распределения статистики критерия при условии, что нулевая гипотеза верна
1. Расчёт выборочной статистики
1. Расчёт p-значения (p-value)
1. Сопоставление уровня значимости $α$ и p-значения (p-value)
1. Статистический вывод
:::

:::{.callout-note}
###### Статистический вывод [Вариант 2]
* Если p-значение *меньше* уровня значимости ($\pval < \alpha$), то мы *имеем основания отклонить нулевую гипотезу* $H_0$ и принять альтернативную $H_1$.
* Если p-значение *больше* уровня значимости ($\pval > \alpha$), то мы **не** *имеем оснований отклонить нулевую гипотезу* $H_0$ и принять альтернативную $H_1$.

:::

#### p-value {#prob-hyptesting-algorithm-opt2-pval}

$$
\begin{align}
H_1&: \theta_1 > \theta_2 \quad \pval \defin{=} \prob(t \geq t_o \mid H_0) \\
H_1&: \theta_1 < \theta_2 \quad \pval \defin{=} \prob(t \leq t_o \mid H_0) \\
H_1&: \theta_1 \neq \theta_2 \quad \pval \defin{=} 2 \min \big( \prob(t \geq t_o \mid H_0), \prob(t \leq t_o \mid H_0)  \big)
\end{align}
$$

***

```{r}
set.seed(99)
iq1 <- rnorm(35, mean = 105, sd = 15) %>% round()
mean(iq1)
BSDA::z.test(iq1, mu = 100, sigma.x = 15, alternative = "greater")
```

```{r}
set.seed(100)
iq2 <- rnorm(32, mean = 105, sd = 15) %>% round()
mean(iq2)
BSDA::z.test(iq2, mu = 100, sigma.x = 15, alternative = "greater")
```



:::{.callout-note}
###### Эквивалентность первого и второго путей

Заметим, что:

* если $\pval < \alpha$, то
    * $t_{o} < t_{\cr}$ для левосторонней альтернативы
    * $t_{o} > t_{\cr}$ для правосторонней альтернативы
    * $t_{o} < t_{\cr1} \or t_{o} > t_{\cr2}$ для двусторонней альтернативы
* если $\pval > \alpha$, то
    * $t_{o} > t_{\cr}$ для левосторонней альтернативы
    * $t_{o} < t_{\cr}$ для правосторонней альтернативы
    * $t_{o} > t_{\cr1} \and t_{o} < t_{\cr2}$ для двусторонней альтернативы
:::


### Визуализация связи ошибок I и II рода {#prob-hyptesting-errorconnection-graph}

:::{.lab-junior}
:::

```{r error-connection-graph}
sig.level <- 0.05
alternative <- list(mean = 1, sd = 1)
lims <- list(left = -3, right = 3)
crit_area <- list(left = qnorm(p = 1 - sig.level), right = lims$right)
beta_area <- list(left = lims$left, right = crit_area$left)
ggplot(NULL) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1),
                geom = "area", xlim = c(crit_area$left, crit_area$right),
                alpha = .5, fill = "red") +
  stat_function(fun = dnorm, args = list(mean = alternative$mean, sd = alternative$sd),
                geom = "area", xlim = c(beta_area$left, beta_area$right),
                alpha = .5, fill = "blue") +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +
  stat_function(fun = dnorm, args = list(mean = alternative$mean, sd = alternative$sd),
                linetype = "dashed") +
  geom_vline(xintercept = crit_area$left, linetype = "dotted") +
  xlim(lims$left, lims$right)
```


```{r error-connection-graph-2}
sig.level <- 0.05
alternative <- list(mean = 1, sd = 1)
lims <- list(left = -3, right = 3)
crit_area <- list(left1 = lims$left, right1 = qnorm(sig.level/2),
                  left2 = qnorm(p = 1 - sig.level/2), right2 = lims$right)
beta_area <- list(left = crit_area$right1, right = crit_area$left2)
ggplot(NULL) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1),
                geom = "area", xlim = c(crit_area$left1, crit_area$right1),
                alpha = .5, fill = "red") +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1),
                geom = "area", xlim = c(crit_area$left2, crit_area$right2),
                alpha = .5, fill = "red") +
  stat_function(fun = dnorm, args = list(mean = alternative$mean, sd = alternative$sd),
                geom = "area", xlim = c(beta_area$left, beta_area$right),
                alpha = .5, fill = "blue") +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1)) +
  stat_function(fun = dnorm, args = list(mean = alternative$mean, sd = alternative$sd),
                linetype = "dashed") +
  geom_vline(xintercept = c(crit_area$right1, crit_area$left2),
             linetype = "dotted") +
  xlim(lims$left, lims$right)
```



## Асимметрия статистического вывода {#prob-hyptesting-inf-asymm}

:::{.lab-junior}
:::


## Алгоритм тестирования статистических гипотез в R {#prob-hyptesting-algorithm-R}

:::{.lab-senior}
:::


### Математика вычисления p-value {#prob-hyptesting-algorithm-pval-math}

:::{.lab-senior}
:::

$$
\begin{align}
H_1&: \theta_1 > \theta_2 \quad \pval = \prob(t \geq t_o \mid H_0) = \int_{t_o}^{+\infty} \dens(t) dt \\
H_1&: \theta_1 < \theta_2 \quad \pval = \prob(t \leq t_o \mid H_0) = \int_{-\infty}^{t_o} \dens(t) dt \\
H_1&: \theta_1 \neq \theta_2 \quad \pval = 2 \min \big( \prob(t \geq t_o \mid H_0), \prob(t \leq t_o \mid H_0)  \big) = 2 \min \Bigg( \int_{t_o}^{+\infty} \dens(t) dt, \int_{-\infty}^{t_o} \dens(t) dt \Bigg)
\end{align}
$$


***

```{r}
set.seed(404)
smpl1 <- rnorm(60, 100, 15)
smpl2 <- rnorm(60, 105, 15)
mu <- 100
s <- 15
BSDA::z.test(smpl1, sigma.x = s, mu = mu)
BSDA::z.test(smpl2, sigma.x = s, mu = mu)

z1 <- (mean(smpl1) - mu) / (s / sqrt(length(smpl1)))
z1
p1 <- 2 * min(
  integrate(f = dnorm,
          mean = 0, sd = 1,
          lower = -Inf,
          upper = z1)$value,
  integrate(f = dnorm,
          mean = 0, sd = 1,
          lower = z1,
          upper = Inf)$value
)
p1

z2 <- (mean(smpl2) - mu) / (s / sqrt(length(smpl2)))
z2
p2 <- 2 * min(
  integrate(f = dnorm,
            mean = 0, sd = 1,
            lower = -Inf,
            upper = z2)$value,
  integrate(f = dnorm,
            mean = 0, sd = 1,
            lower = z2,
            upper = Inf)$value
)
p2
```


***

###### Session Info {#session_info .unnumbered}

```{r session-info}
sessionInfo()
```

```{=html}
<script type="text/javascript" src="./js/chapter.js"></script>
```
